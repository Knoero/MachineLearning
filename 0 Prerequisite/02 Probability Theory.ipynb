{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8c8fd50",
   "metadata": {},
   "source": [
    "**Information:** A brief review of basic concepts of Probability related theory used in Machine Learning\n",
    "\n",
    "**Written by:** Zihao Xu\n",
    "\n",
    "**Last update date:** 05.23.2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0425562",
   "metadata": {},
   "source": [
    "# Basic concepts\n",
    "## Introduction\n",
    "### Definition: \n",
    "- Probability Theory is a mathematical frame work for representing uncertain statements\n",
    "    - Provides a means of quantifying uncertainty as well as axioms for deriving new uncertainty statements\n",
    "    - Allows making uncertain statements and reasoning in the presence of uncertainty\n",
    "\n",
    "### Motivation: \n",
    "- Machine learning must always deal with uncertain quantities and sometimes stochastic (non-deterministic) quantities resulting from:\n",
    "    - Inherent stochasticity in the system being modeled\n",
    "    - Incomplete observability\n",
    "    - Incomplete modeling\n",
    "- It's usually more practical to use a *simple but uncertain rule* rather than a complex but certain one\n",
    "    - \"Most birds fly\" versus \"Birds fly, except for ...\"\n",
    "- Uncertainty can be modeled by probability\n",
    "\n",
    "### Interpretation of probability\n",
    "- **Frequentist probability**\n",
    "    - Probability theory was originally developed to analyze the *frequencies of events*, which are often *repeatable*\n",
    "    - When we say that an outcome has a probability $p$ of occurring, it means that if we repeated the experiment infinitely times, then a proportion $p$ of the repetitions would result in that outcome\n",
    "    - Not seemingly applicable to propositions that are not repeatable\n",
    "- **Bayesian probability**\n",
    "    - Use probability to represent a *degree of belief* for an outcome to occur, with 1 indicating absolute certainty that the outcome occurs and 0 indicating absolute certainty that the outcome doesn't occur\n",
    "    - For properties that we expect common sense reasoning about uncertainty to have, we need to treat Bayesian probabilities as behaving exactly the same as frequentist probabilities.\n",
    "- **The extension logic to deal with uncertainty**\n",
    "    - Probability can be seen as the extension of logic to deal with uncertainty. Probability theory provides a set of formal rules for determining the likelihood of a proposition being true given the likelihood of other propositions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8913f8af",
   "metadata": {},
   "source": [
    "## Probability Space\n",
    "- A *probability space* is defined by the triple $\\left(\\Omega,\\mathcal{F},P\\right)$, where:\n",
    "    - $\\Omega$ is the *space of possible outcomes* (or outcome space)\n",
    "    - $\\mathcal{F}\\subseteq2^{\\Omega}$ is the *space of (measurable) events* (or event space)\n",
    "    - $P$ is the *probability measure* (or *probability distribution*) that maps an event $E\\in \\mathcal{F}$ to a real value between $0$ and $1$ (think of $P$ as a function)\n",
    "- Given an outcome space $\\Omega$, there is some restrictions as to what subset of $2^{\\Omega}$ can be considered an event space $\\mathcal{F}$:\n",
    "    - The trivial event $\\Omega$ and the empty event $\\mathbb{0}$ is in $\\mathcal{F}$\n",
    "    - The event space $\\mathcal{F}$ is closed under (countable) union\n",
    "        - if $\\alpha,\\beta\\in\\mathcal{F}$, then $\\alpha\\cup\\beta\\in\\mathcal{F}$\n",
    "    - The event space $\\mathcal{F}$ is closed under complement\n",
    "        - if $\\alpha\\in\\mathcal{F}$, then $(\\Omega \\setminus \\alpha)\\in\\mathcal{F}$\n",
    "- Notice: Event space is not always simply the power set of the outcome space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d840babb",
   "metadata": {},
   "source": [
    "## Random Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993031e5",
   "metadata": {},
   "source": [
    "### Definition\n",
    "- A *random variable* is a function maps outcomes in the outcome space $\\Omega$ to real values\n",
    "    - **Not random nor a variable** \n",
    "- May be discrete or continuous\n",
    "    - Discrete: When the image of a random variable is countable, the random variable is called a *discrete random variable*\n",
    "    - Continuous: When the image of random variable is uncountably infinite (usually an interval), then the random variable is called a *continuous random variable*\n",
    "    - [Image](https://en.wikipedia.org/wiki/Image_(mathematics)):In mathematics, the image of a function is the set of all output values it may produce.\n",
    "\n",
    "### Notation\n",
    "- Upper case letters to represent random variables\n",
    "    - $X,Y,Z,...$\n",
    "- Lower case letters to represent the values of random variables\n",
    "    - $x,y,z,...$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a3cef2",
   "metadata": {},
   "source": [
    "## Probability Distributions\n",
    "- A **probability distribution** is a description of how likely a random variable or set of random variables is to take on each of its possible states. The way to describe probability distribution depends on whether the variables are discrete or continuous.\n",
    "\n",
    "### Discrete Variables and Probability Mass Functions\n",
    "- **Probability Mass Function (PMF)**: A function that gives the probability a discrete random variable is exactly equal to some value\n",
    "    - Called probability mass function as it divides up a unit mass (the total probability) and places them on different values a random variable can take\n",
    "    - Sometimes called *discrete density function*\n",
    "    - The primary means of defining a discrete probability distribution\n",
    "- **Notations for PMF**: \n",
    "    - Let $X$ be a discrete random variable, the probability mass function of $X$ is:\n",
    "$$P(X=x)=\\mathrm{Probability}\\  \\mathrm{that}\\  \\mathrm{the}\\  \\mathrm{random}\\  \\mathrm{variable}\\ X\\ \\mathrm{takes}\\  \\mathrm{the}\\  \\mathrm{value}\\ x$$\n",
    "        - Can be written in $p_X(x)$ or even directly $p(x)$ when there is no ambiguity\n",
    "    - Sometimes we define a variable first, then use $\\sim$ notation to specify which distribution it follows later: $X\\sim P(X)$\n",
    "- **Properties of PMF**: Given that $X$ is a *discrete random variable*, then:\n",
    "    - The domain of $p$ must be the set of all possible states of $X$\n",
    "    - $\\forall x\\in X,0\\le p(x)\\le 1.$ An impossible event has probability $0$, and no state can be less probable than that. Likewise, an event that is guaranteed to happen has probability $1$, and no state can have a greater chance of occurring\n",
    "    - $\\underset{x}{\\Sigma}p(x)=1$.Usually refer to this property as being *normalized*.\n",
    "    - Probability of $X$ taking either the value $x_1$ or the value $x_2$ (assuming $x_1\\ne x_2$) is:$$P(X=x_1\\ \\mathrm{or}\\ X=x_2)\\equiv P(X\\in\\{x_1,x_2\\})=P(X=x_1)+P(X=x_2)=p(x_1)+p(x_2)$$\n",
    "        - More generally, the probability that the random variable $X$ takes any value in a set $A$ is given by $P(X\\in A)=\\underset{x\\in A}{\\Sigma}p(x)$ \n",
    "    - Let $g(x)$ be a function and $Y=g(X)$ be a new random variable, then the PMF would be: $$P(y)=P(Y=y)=\\underset{x\\in g^{-1}(y)}{\\Sigma}p(x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5588c66a",
   "metadata": {},
   "source": [
    "### Continuous Variables and Probability Density Functions\n",
    "- **Cumulative Distribution Function(CDF)**:A function that gives the probability that a random variable will take a value less than some value\n",
    "    - The random variable can be either discrete or continuous\n",
    "    - Sometimes called *distribution function*\n",
    "- **Notations for CDF**\n",
    "    - Let $X$ be a random variable, then its cumulative distribution function is denoted by:$$F(x)=P(X\\le x)$$\n",
    "- **Properties of CDF**: Given that $X$ is a random variable, then:\n",
    "    - The domain of $F$ must be the set of all possible states of $X$\n",
    "    - $F(x)$ is an increasing function for $x$\n",
    "    - $F(-\\infty)=\\underset{x\\rightarrow -\\infty}{\\mathrm{lim}}F(x)=0$ \n",
    "    - $F(+\\infty)=\\underset{x\\rightarrow - \\infty}{\\mathrm{lim}}F(x)=1$\n",
    "    - $P(a\\le X \\le b)=F(b)-F(a)$\n",
    "\n",
    "- **Probability Density Function (PDF)**: A function whose value at any given sample in the sample space (the set of possible values taken by the random variable) can be interpreted as providing a *relative likelihood* that the value of the random variable would equal that sample\n",
    "    - Definition only for continuous random variables\n",
    "    - While the *absolute likelihood* for a continuous random variable to take on any particular value is 0 (since there is an infinite set of possible values to begin with), the value of the PDF at two different samples can be used to infer how much more likely it is that the random variable would equal one sample compared to the other sample.\n",
    "- **Notations for PDF**\n",
    "    - Let $X$ be a continuous random variable, then its probability density function is denoted by:$$p(x)\\simeq\\frac{P(x\\le X \\le x+\\Delta x)}{\\Delta x}$$ for some small $\\Delta x$ according to definition\n",
    "    - Observation:$$\\begin{aligned}p(x)&=\\underset{\\Delta x\\rightarrow 0}{\\mathrm{lim}}\\frac{P(x\\le X \\le x+\\Delta x)}{\\Delta x}\\\\&=\\underset{\\Delta x\\rightarrow 0}{\\mathrm{lim}}\\frac{F(x+\\Delta x)-F(x)}{\\Delta x}\\\\&=F'(x)\\\\&=\\frac{\\mathrm{d}F(x)}{\\mathrm{d}x}\\end{aligned}$$\n",
    "- **Properties of PDF**: Given that $X$ is a *continuous random variable*, then:\n",
    "    - The domain of $p$ must be the set of all possible states of $X$\n",
    "    - $\\forall x \\in X,p(x)\\ge 0$. Note that $p(x)\\le 1$ is not required\n",
    "    - $\\int p(x)dx=1$\n",
    "    - $\\int^b_a p(x)dx=F(b)-F(a)=P(a\\le X \\le b)$\n",
    "    - For any [borel](https://en.wikipedia.org/wiki/Borel_set) subset $A$ of the real numbers:$$P(X\\in A)=\\int_Ap(x)dx$$. This property holds even for random vectors \n",
    "    - Let $g(x)$ be a function and $Y=g(X)$ be a new continuous random variable, then the PDF of $Y$ would be:$$p(y)=p(x=g^{-1}(y))|\\frac{d}{dy}(g^{-1}(y))|$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ee0fa0",
   "metadata": {},
   "source": [
    "## Expectations and Variance\n",
    "### Expectations\n",
    "- **Definition**: The **expectation**, or **expected value**, of a random variable is denoted by $\\mathrm{E}(X)$\n",
    "    - For a discrete random variable $X$: $$\\mathrm{E}[X]=\\underset{x}{\\Sigma}xp(x)$$ where $P(x)$ is the probability mass function and the sum is over all possible values\n",
    "    - For a continuous random variable $X$: $$\\mathrm{E}[X]=\\int_{x} xp(x)dx$$ where $p(x)$ is the probability density function and the integral is over all possible values\n",
    "    - Can think of the expectation as the value of the random variable that one should \"expect\" to get, but notice that the expectation of a random variable is usually not in the possible values of it.\n",
    "- **Properties**: Let $X$ be a random variable, then:\n",
    "    - Let $g(x)$ be a function:\n",
    "        - For a discrete random variable $X$: $$\\mathrm{E}[g(X)]=\\underset{x}{\\Sigma}g(x)p(x)$$\n",
    "        - For a continuous random variable $X$: $$\\mathrm{E}[g(X)]=\\int_xg(x)p(x)dx$$\n",
    "    - Take any constant $c$: $$\\mathrm{E}[X+c]=\\mathrm{E}[X]+c$$\n",
    "    - Take any constant $\\lambda$: $$\\mathrm{E}[\\lambda X]=\\lambda\\mathrm{E}[X]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee8f938",
   "metadata": {},
   "source": [
    "### Variance\n",
    "- **Definition**: The **variance** measures how much the value of a function of a random variable vary as sampling different values from its probability distribution\n",
    "    - For a discrete/continuous random variable $X$:$$\\mathrm{V}[X]=\\mathrm{E}\\left[\\left(X-\\mathrm{E}[X]\\right)^2\\right]$$\n",
    "    - Can think of the variance as the spread of the random variable around its expectation\n",
    "    - Square root of the variance is known as the **standard deviation**\n",
    "- **Properties**:\n",
    "    - $\\mathrm{V}[X]=\\mathrm{E}[X^2]-(\\mathrm{E[X]})^2$\n",
    "    - Take any constant $c$: $$\\mathrm{V}[X+c]=\\mathrm{V}[X]$$\n",
    "    - Take any constant $\\lambda$: $$\\mathrm{V}[\\lambda X]=\\lambda^2\\mathrm{V}[X]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7e535f",
   "metadata": {},
   "source": [
    "## Collections of Random Variables\n",
    "### Joint Distributions, Marginal Distributions and Conditional Distributions\n",
    "- **Joint Distributions**: Distributions over multiple random variables\n",
    "    - For discrete random variables $X$ and $Y$, the **joint probability mass function** of the pair $(X,Y)$ is the function $p(x,y)$ giving the probability that $X=x$ and $Y=y$ is denoted as:$$p(x,y)=P(X=x,Y=y)$$\n",
    "        - It's non-negative: $p(x,y)\\ge 0$\n",
    "        - Sum over all the possible values of all random variables is 1: $\\underset{x}{\\Sigma}\\underset{y}{\\Sigma}p(x,y)=1$\n",
    "        - *Sum Rule*: Marginalizing over the values of one of the random variables gets the PMF of the other: $\\underset{y}{\\Sigma}p(x,y)=p(x),\\underset{x}{\\Sigma}p(x,y)=p(y)$. This result is called the **Marginal Distribution**.\n",
    "    - For continuous random variables $X$ and $Y$, the **joint probability density function** of the pair $(X,Y)$ is the function $p(x,y)$ giving the probability that $X=x$ and $Y=y$:$$p(x,y)=\\underset{\\Delta x,\\Delta y\\rightarrow 0}{\\mathrm{lim}}\\frac{P(x\\le X\\le x+\\Delta x,y\\le Y \\le y+\\Delta y)}{\\Delta x\\Delta y}$$\n",
    "        - It's non-negative: $p(x,y)\\ge 0$\n",
    "        - Sum over all the possible values of all random variables is 1: $\\int\\int p(x,y)dxdy=1$\n",
    "        - *Sum Rule*: Marginalizing over the values of one of the random variables gets the PDF of the other:$\\int p(x,y)dy=p(x)$ and $\\int p(x,y)dx=p(y)$. The result is called the **Marginal Distribution**\n",
    "- **Conditional Distributions**: In many cases, the probability of some event given that some other event has happened is wanted. This called a **conditional probability**\n",
    "    - For random variables $X$ and $Y$, if $X=x$ is observed and the state of knowledge about $Y$ is need to be updated, then the conditional PDF is:$$P(Y=y|X=x)=p(y|x)=\\frac{P(X=x,Y=y)}{P(X=x)}=\\frac{p(x,y)}{p(x)}$$\n",
    "        - The conditional probability is only defined when $P(X=x)>0$. The conditional probability conditioned on an event that never happens is meaningless.\n",
    "    - Chain Rule / Product Rule of Conditional Probabilities $$P(x^{(1)},\\cdots,x^{(n)})=P(x^{(1)})\\underset{i=2}{\\overset{n}{\\Pi}}P(x^{i}|x^{(1)},\\cdots,x^{(i-1)})$$\n",
    "        - For example: $$\\begin{aligned}p(a,b,c)&=p(a|b,c)p(b,c)\\\\p(b,c)&=p(b|c)p(c)\\\\p(a,b,c)&=p(a|b,c)p(b|c)p(c)\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c09aa50",
   "metadata": {},
   "source": [
    "### Expectations\n",
    "- Take two random variables $X$ and $Y$ with joint PDF $p(x,y)$, the expectation of their sum is $$\\mathrm{E}[X+Y]=\\mathrm[X]+\\mathrm[Y]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd773ebc",
   "metadata": {},
   "source": [
    "### Correlated Random Variables\n",
    "- **Covariance**: A measure of the jointly variability of two random variables\n",
    "    - Gives some sense of how much two values are linearly related to each other\n",
    "    - For two jointly distributed random variables $X$ and $Y$, the covariance is defined as:$$\\mathrm{cov}(X,Y)=\\mathrm{E}[(X-\\mathrm{E}[X])(Y-\\mathrm{E}[Y])]$$\n",
    "    - Correlation is not causation\n",
    "    - Two jointly distributed random variables $X$ and $Y$ is called:\n",
    "        - positively correlated if $\\mathrm{cov}(X,Y)>0$\n",
    "        - negatively correlated if $\\mathrm{cov}(X,Y)<0$\n",
    "        - uncorrelated if $\\mathrm{cov}(X,Y)\\approx 0$\n",
    "- **Properties of the covariance**:\n",
    "    - Let $X$ be a random variable: $$\\mathrm{cov}[X,X]=\\mathrm{V}[X]$$\n",
    "    - Let $X$ be a random variable and take any constant $\\lambda$: $$\\mathrm{cov}[X,\\lambda]=0$$\n",
    "    - Let $X$ and $Y$ be two random variables: $$\\mathrm{cov}[Y,X]=\\mathrm{cov}[X,Y]$$\n",
    "    - Let $X$ and $Y$ be two random variables and take any constants: $$\\mathrm{cov}[\\lambda X,\\mu Y]=\\lambda\\mu\\mathrm{cov}[X,Y]$$\n",
    "    - Let $X$ and $Y$ be two random variables and take any constants: $$\\mathrm{cov}[X+\\lambda,Y+\\mu]=\\mathrm{cov}[X,Y]$$\n",
    "    - Let $X$, $Y$ and $Z$ be three random variables: $$\\mathrm{cov}[X,Y+Z]=\\mathrm{cov}[X,Y]+\\mathrm{cov}[X,Z]$$\n",
    "    - Let $X$ and $Y$ be two random variable: $$\\mathrm{V}[X+Y]=\\mathrm{V}[X]+\\mathrm{V}[Y]+2\\mathrm{cov}[X,Y]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344ceeb2",
   "metadata": {},
   "source": [
    "### Independent Random Variables\n",
    "- **Definition**: Two random variables $X$ and $Y$ are independent conditional on $I$, denoted as $X\\perp Y|I$ if and only if conditioning on one does not tell anything about the other $$p(x|y,I)=p(x|I)$$\n",
    "    - When there is no ambiguity, $I$ can be dropped\n",
    "- **Properties**: Assume $X$ and $Y$ are two independent random variables, then:\n",
    "    - $p(x,y)=p(x)p(y)$\n",
    "    - $\\mathrm{E}[XY]=\\mathrm{E}[X]\\mathrm{E}[Y]$\n",
    "    - $\\mathrm{cov}[X,Y]=0$\n",
    "        - The reverse is not true. Uncorrelated variables do not have to be independent\n",
    "    - $\\mathrm{V}[X+Y]=\\mathrm{V}[X]+\\mathrm{V}[Y]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfea423b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
