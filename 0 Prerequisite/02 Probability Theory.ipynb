{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8c8fd50",
   "metadata": {},
   "source": [
    "**Information:** A brief review of basic concepts of Probability and Statistics related theory which is often used in Machine Learning\n",
    "\n",
    "**Written by:** Zihao Xu\n",
    "\n",
    "**Last update date:** 05.23.2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0425562",
   "metadata": {},
   "source": [
    "# Basic concepts\n",
    "## Introduction\n",
    "### Definition: \n",
    "- Probability Theory is a mathematical frame work for representing uncertain statements\n",
    "    - Provides a means of quantifying uncertainty as well as axioms for deriving new uncertainty statements\n",
    "    - Allows making uncertain statements and reasoning in the presence of uncertainty\n",
    "\n",
    "### Motivation: \n",
    "- Machine learning must always deal with uncertain quantities and sometimes stochastic (non-deterministic) quantities resulting from:\n",
    "    - Inherent stochasticity in the system being modeled\n",
    "    - Incomplete observability\n",
    "    - Incomplete modeling\n",
    "- It's usually more practical to use a *simple but uncertain rule* rather than a complex but certain one\n",
    "    - \"Most birds fly\" versus \"Birds fly, except for ...\"\n",
    "- Uncertainty can be modeled by probability\n",
    "\n",
    "### Interpretation of probability\n",
    "- **Frequentist probability**\n",
    "    - Probability theory was originally developed to analyze the *frequencies of events*, which are often *repeatable*\n",
    "    - When we say that an outcome has a probability $p$ of occurring, it means that if we repeated the experiment infinitely times, then a proportion $p$ of the repetitions would result in that outcome\n",
    "    - Not seemingly applicable to propositions that are not repeatable\n",
    "- **Bayesian probability**\n",
    "    - Use probability to represent a *degree of belief* for an outcome to occur, with 1 indicating absolute certainty that the outcome occurs and 0 indicating absolute certainty that the outcome doesn't occur\n",
    "    - For properties that we expect common sense reasoning about uncertainty to have, we need to treat Bayesian probabilities as behaving exactly the same as frequentist probabilities.\n",
    "- **The extension logic to deal with uncertainty**\n",
    "    - Probability can be seen as the extension of logic to deal with uncertainty. Probability theory provides a set of formal rules for determining the likelihood of a proposition being true given the likelihood of other propositions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8913f8af",
   "metadata": {},
   "source": [
    "## Probability Space\n",
    "- A *probability space* is defined by the triple $\\left(\\Omega,\\mathcal{F},P\\right)$, where:\n",
    "    - $\\Omega$ is the *space of possible outcomes* (or outcome space)\n",
    "    - $\\mathcal{F}\\subseteq2^{\\Omega}$ is the *space of (measurable) events* (or event space)\n",
    "    - $P$ is the *probability measure* (or *probability distribution*) that maps an event $E\\in \\mathcal{F}$ to a real value between $0$ and $1$ (think of $P$ as a function)\n",
    "- Given an outcome space $\\Omega$, there is some restrictions as to what subset of $2^{\\Omega}$ can be considered an event space $\\mathcal{F}$:\n",
    "    - The trivial event $\\Omega$ and the empty event $\\mathbb{0}$ is in $\\mathcal{F}$\n",
    "    - The event space $\\mathcal{F}$ is closed under (countable) union\n",
    "        - if $\\alpha,\\beta\\in\\mathcal{F}$, then $\\alpha\\cup\\beta\\in\\mathcal{F}$\n",
    "    - The event space $\\mathcal{F}$ is closed under complement\n",
    "        - if $\\alpha\\in\\mathcal{F}$, then $(\\Omega \\setminus \\alpha)\\in\\mathcal{F}$\n",
    "- Notice: Event space is not always simply the power set of the outcome space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d840babb",
   "metadata": {},
   "source": [
    "## Random Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993031e5",
   "metadata": {},
   "source": [
    "### Definition\n",
    "- A *random variable* is a function maps outcomes in the outcome space $\\Omega$ to real values\n",
    "    - **Not random nor a variable** \n",
    "- May be discrete or continuous\n",
    "    - Discrete: When the image of a random variable is countable, the random variable is called a *discrete random variable*\n",
    "    - Continuous: When the image of random variable is uncountably infinite (usually an interval), then the random variable is called a *continuous random variable*\n",
    "    - [Image](https://en.wikipedia.org/wiki/Image_(mathematics)):In mathematics, the image of a function is the set of all output values it may produce.\n",
    "\n",
    "### Notation\n",
    "- Upper case letters to represent random variables\n",
    "    - $X,Y,Z,...$\n",
    "- Lower case letters to represent the values of random variables\n",
    "    - $x,y,z,...$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a3cef2",
   "metadata": {},
   "source": [
    "## Probability Distributions\n",
    "- A **probability distribution** is a description of how likely a random variable or set of random variables is to take on each of its possible states. The way to describe probability distribution depends on whether the variables are discrete or continuous.\n",
    "\n",
    "### Discrete Variables and Probability Mass Functions\n",
    "- **Probability Mass Function (PMF)**: A function that gives the probability a discrete random variable is exactly equal to some value\n",
    "    - Called probability mass function as it divides up a unit mass (the total probability) and places them on different values a random variable can take\n",
    "    - Sometimes called *discrete density function*\n",
    "    - The primary means of defining a discrete probability distribution\n",
    "- **Notations for PMF**: \n",
    "    - Let $X$ be a discrete random variable, the probability mass function of $X$ is:\n",
    "$$P(X=x)=\\mathrm{Probability}\\  \\mathrm{that}\\  \\mathrm{the}\\  \\mathrm{random}\\  \\mathrm{variable}\\ X\\ \\mathrm{takes}\\  \\mathrm{the}\\  \\mathrm{value}\\ x$$\n",
    "        - Can be written in $p_X(x)$ or even directly $p(x)$ when there is no ambiguity\n",
    "    - Sometimes we define a variable first, then use $\\sim$ notation to specify which distribution it follows later: $X\\sim P(X)$\n",
    "- **Properties of PMF**: Given that $X$ is a *discrete random variable*, then:\n",
    "    - The domain of $p$ must be the set of all possible states of $X$\n",
    "    - $\\forall x\\in X,0\\le p(x)\\le 1.$ An impossible event has probability $0$, and no state can be less probable than that. Likewise, an event that is guaranteed to happen has probability $1$, and no state can have a greater chance of occurring\n",
    "    - $\\underset{x}{\\Sigma}p(x)=1$.Usually refer to this property as being *normalized*.\n",
    "    - Probability of $X$ taking either the value $x_1$ or the value $x_2$ (assuming $x_1\\ne x_2$) is:$$P(X=x_1\\ \\mathrm{or}\\ X=x_2)\\equiv P(X\\in\\{x_1,x_2\\})=P(X=x_1)+P(X=x_2)=p(x_1)+p(x_2)$$\n",
    "        - More generally, the probability that the random variable $X$ takes any value in a set $A$ is given by $P(X\\in A)=\\underset{x\\in A}{\\Sigma}p(x)$ \n",
    "    - Let $g(x)$ be a function and $Y=g(X)$ be a new random variable, then the PMF would be: $$P(y)=P(Y=y)=\\underset{x\\in g^{-1}(y)}{\\Sigma}p(x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5588c66a",
   "metadata": {},
   "source": [
    "### Continuous Variables and Probability Density Functions\n",
    "- **Cumulative Distribution Function(CDF)**:A function that gives the probability that a random variable will take a value less than some value\n",
    "    - The random variable can be either discrete or continuous\n",
    "    - Sometimes called *distribution function*\n",
    "- **Notations for CDF**\n",
    "    - Let $X$ be a random variable, then its cumulative distribution function is denoted by:$$F(x)=P(X\\le x)$$\n",
    "- **Properties of CDF**: Given that $X$ is a random variable, then:\n",
    "    - The domain of $F$ must be the set of all possible states of $X$\n",
    "    - $F(x)$ is an increasing function for $x$\n",
    "    - $F(-\\infty)=\\underset{x\\rightarrow -\\infty}{\\mathrm{lim}}F(x)=0$ \n",
    "    - $F(+\\infty)=\\underset{x\\rightarrow - \\infty}{\\mathrm{lim}}F(x)=1$\n",
    "    - $P(a\\le X \\le b)=F(b)-F(a)$\n",
    "\n",
    "- **Probability Density Function (PDF)**: A function whose value at any given sample in the sample space (the set of possible values taken by the random variable) can be interpreted as providing a *relative likelihood* that the value of the random variable would equal that sample\n",
    "    - Definition only for continuous random variables\n",
    "    - While the *absolute likelihood* for a continuous random variable to take on any particular value is 0 (since there is an infinite set of possible values to begin with), the value of the PDF at two different samples can be used to infer how much more likely it is that the random variable would equal one sample compared to the other sample.\n",
    "- **Notations for PDF**\n",
    "    - Let $X$ be a continuous random variable, then its probability density function is denoted by:$$p(x)\\simeq\\frac{P(x\\le X \\le x+\\Delta x)}{\\Delta x}$$ for some small $\\Delta x$ according to definition\n",
    "    - Observation:$$\\begin{aligned}p(x)&=\\underset{\\Delta x\\rightarrow 0}{\\mathrm{lim}}\\frac{P(x\\le X \\le x+\\Delta x)}{\\Delta x}\\\\&=\\underset{\\Delta x\\rightarrow 0}{\\mathrm{lim}}\\frac{F(x+\\Delta x)-F(x)}{\\Delta x}\\\\&=F'(x)\\\\&=\\frac{\\mathrm{d}F(x)}{\\mathrm{d}x}\\end{aligned}$$\n",
    "- **Properties of PDF**: Given that $X$ is a *continuous random variable*, then:\n",
    "    - The domain of $p$ must be the set of all possible states of $X$\n",
    "    - $\\forall x \\in X,p(x)\\ge 0$. Note that $p(x)\\le 1$ is not required\n",
    "    - $\\int p(x)dx=1$\n",
    "    - $\\int^b_a p(x)dx=F(b)-F(a)=P(a\\le X \\le b)$\n",
    "    - For any [borel](https://en.wikipedia.org/wiki/Borel_set) subset $A$ of the real numbers:$$P(X\\in A)=\\int_Ap(x)dx$$. This property holds even for random vectors \n",
    "    - Let $g(x)$ be a function and $Y=g(X)$ be a new continuous random variable, then the PDF of $Y$ would be:$$p(y)=p(x=g^{-1}(y))|\\frac{d}{dy}(g^{-1}(y))|$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ee0fa0",
   "metadata": {},
   "source": [
    "## Expectations and Variance\n",
    "### Expectations\n",
    "- **Definition**: The **expectation**, or **expected value**, of a random variable is denoted by $\\mathbb{E}(X)$\n",
    "    - For a discrete random variable $X$: $$\\mathbb{E}[X]=\\underset{x}{\\Sigma}xp(x)$$ where $P(x)$ is the probability mass function and the sum is over all possible values\n",
    "    - For a continuous random variable $X$: $$\\mathbb{E}[X]=\\int_{x} xp(x)dx$$ where $p(x)$ is the probability density function and the integral is over all possible values\n",
    "    - Can think of the expectation as the value of the random variable that one should \"expect\" to get, but notice that the expectation of a random variable is usually not in the possible values of it.\n",
    "- **Properties**: Let $X$ be a random variable, then:\n",
    "    - Let $g(x)$ be a function:\n",
    "        - For a discrete random variable $X$: $$\\mathbb{E}[g(X)]=\\underset{x}{\\Sigma}g(x)p(x)$$\n",
    "        - For a continuous random variable $X$: $$\\mathbb{E}[g(X)]=\\int_xg(x)p(x)dx$$\n",
    "    - Take any constant $c$: $$\\mathbb{E}[X+c]=\\mathbb{E}[X]+c$$\n",
    "    - Take any constant $\\lambda$: $$\\mathbb{E}[\\lambda X]=\\lambda\\mathbb{E}[X]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee8f938",
   "metadata": {},
   "source": [
    "### Variance\n",
    "- **Definition**: The **variance** measures how much the value of a function of a random variable vary as sampling different values from its probability distribution\n",
    "    - For a discrete/continuous random variable $X$:$$\\mathbb{V}[X]=\\mathbb{E}\\left[\\left(X-\\mathbb{E}[X]\\right)^2\\right]$$\n",
    "    - Can think of the variance as the spread of the random variable around its expectation\n",
    "    - Square root of the variance is known as the **standard deviation**\n",
    "- **Properties**:\n",
    "    - $\\mathbb{V}[X]=\\mathbb{E}[X^2]-(\\mathbb{E}[X])^2$\n",
    "    - Take any constant $c$: $$\\mathbb{V}[X+c]=\\mathbb{V}[X]$$\n",
    "    - Take any constant $\\lambda$: $$\\mathbb{V}[\\lambda X]=\\lambda^2\\mathbb{V}[X]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b7b290",
   "metadata": {},
   "source": [
    "## Some Important Distributions\n",
    "### Bernoulli\n",
    "- The *Bernoulli Distribution* is one of the most basic distribution. It is a distribution over a single binary random variable and is controlled by a single parameter $\\theta\\in[0,1]$, which gives the probability of the random variable being equal to $1$.\n",
    "- For a *discrete random variable* $X$ following a Bernoulli distribution with parameter $\\theta$, the notation is: $$X\\sim \\mathrm{Bernoulli}(\\theta)$$\n",
    "- Properties:\n",
    "    - $P(X=1)=\\theta$\n",
    "    - $P(X=0)=1-\\theta$\n",
    "    - $P(X=x)=\\theta^{x}(1-\\theta)^{1-x}$ where $x=0$ or $x=1$\n",
    "    - $\\mathbb{E}[X]=\\theta$\n",
    "    - $\\mathbb{V}[X]=\\theta(1-\\theta)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f144f2",
   "metadata": {},
   "source": [
    "### Categorical Distribution\n",
    "- The *Categorical Distribution*, also called *Multinoulli Distribution*, is a distribution over a single discrete random variable with $k$ different states, where $k$ is finite. It is parameterized by a vector $\\mathbf{p}\\in[0,1]^{k-1}$, where $p_i$ gives the probability of the $i-th$ state. The final, $k$-th state's probability is given by $1-\\mathbf{1}^T\\mathbf{p}$, where $\\mathbf{1}^T\\mathbf{p}$ should be constrained to less than or equal to $1$.\n",
    "- For a *discrete random variable* $X$ following a Categorical distribution with parameter $\\mathbf{p}$. the notation is:$$X\\sim \\mathrm{Categorical}(p_1,p_2,\\cdots,p_{k-1},1-\\mathbf{1}^T\\mathbf{p})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ef8c17",
   "metadata": {},
   "source": [
    "### Continuous Uniform Distribution\n",
    "- The *Continuous Uniform Distribution*, also called *rectangular distribution*, models a random variable the takes values within an interval all with equal probability. The interval is defined by the parameters $a$ and $b$, which are the minimum and maximum values. The interval can either be *closed* (i.e. $[a,b]$) or *open* (e.g. $(a,b)$)\n",
    "- For a *continuous random variable* $X$ following a Uniform distribution in the interval $[a,b]$, the notation is:$$X\\sim U([a,b])$$\n",
    "- Probability density function:\n",
    "    - $p(x)=\\left\\{\\begin{aligned}&c &x\\in[a,b]\\\\&0 &\\mathrm{otherwise} \\end{aligned}\\right.$\n",
    "    - $\\int^b_ap(x)dx=1\\Rightarrow c=\\frac{1}{b-a}$\n",
    "- Cumulative distribution function:\n",
    "    - $F(x)=\\left\\{\\begin{aligned}&0 &\\mathrm{if}\\ x<a\\\\ &\\frac{x-a}{b-a} &\\mathrm{if}\\ a\\le x\\le b\\\\ &1 &\\mathrm{otherwise}\\end{aligned}\\right.$\n",
    "- Expectation:\n",
    "    - $\\mathbb{E}[X]=\\frac{a+b}{2}$\n",
    "- Variation:\n",
    "    - $\\mathbb{V}[X]=\\frac{(b-a)^2}{12}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1334785",
   "metadata": {},
   "source": [
    "### Gaussian Distribution\n",
    "- The *Gaussian Distribution*, also know as the *normal distribution*, is the most commonly used distribution over real numbers. It models a random variable that take values from any real value. The distribution is controlled by two parameters $\\mu\\in\\mathbb{R}$ and $\\sigma\\in(0,\\infty)$. The values are concentrated around $\\mu$ and the variance $\\sigma^2$ determines how spread out the function values are around the mean.\n",
    "- For a *continuous random variable* following a Gaussian distribution with expectation $\\mu$ and variance $\\sigma^2$, the notation is:$$X\\sim \\mathcal{N}(\\mu,\\sigma^2)$$ \n",
    "- Probability density function:\n",
    "    - $p(x)=\\mathcal{N}(x|\\mu,\\sigma^2)=\\frac{1}{\\sqrt{2\\pi}\\sigma}\\mathrm{exp}\\left(-\\frac{1}{2\\sigma^2}(x-\\mu)^2\\right)$\n",
    "    - When we need to frequently evaluate the PDF with different parameter values, a more efficient way of parameterizing the distribution is to use a parameter $\\beta\\in(0,\\infty)$ to control the **precision**, or inverse variance, of the distribution\n",
    "        - $\\beta=\\frac{1}{\\sigma^2}$\n",
    "        - $p(x)=\\mathcal{N}(x|\\mu,\\beta^{-1})=\\sqrt{\\frac{\\beta}{2\\pi}}\\mathrm{exp}\\left(-\\frac{1}{2}\\beta(x-\\mu)^2\\right)$\n",
    "- Cumulative distribution function is not *analytically* available:\n",
    "    - $F(x)=P(X\\le x)=\\int^x_{-\\infty}\\mathcal{N}(\\bar{x}|\\mu,\\sigma^2)d\\bar{x}$\n",
    "- Expectation:\n",
    "    - $\\mathbb{E}[X]=\\mu$\n",
    "- Variation:\n",
    "    - $\\mathbb{V}[X]=\\sigma^2$\n",
    "- Remark:\n",
    "    - $P(\\mu-2\\sigma\\le x\\le \\mu+2\\sigma)\\approx 95.45\\%$\n",
    "    - $P(\\mu-3\\sigma\\le x\\le \\mu+3\\sigma)\\approx 99.73\\%$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2752c43",
   "metadata": {},
   "source": [
    "### Standard Normal Distribution\n",
    "- The *Standard Normal Distribution* is the simplest case of a *Gaussian Distribution* where $\\mu=0$ and $\\sigma=1$, denoted as:$$Z\\sim\\mathcal{N}(0,1)$$\n",
    "- Probability density function:\n",
    "    - $\\phi(z)=\\mathcal{N}(z|0,1)=\\frac{1}{\\sqrt{2\\pi}}\\mathrm{exp}\\left\\{-\\frac{z^2}{2}\\right\\}$\n",
    "- Cumulative distribution function is also not analytically available:\n",
    "    - $\\Phi(z)=\\frac{1}{\\sqrt{2\\pi}}\\int^z_{-\\infty}\\mathrm{exp}\\left\\{-\\frac{t^2}{2}\\right\\}dt$\n",
    "- Connections between the normal and the standard normal:\n",
    "    - Take a stander normal $Z\\sim\\mathcal{N}(0,1)$ and two numbers $\\mu$ and $\\sigma^2$, make the random variable $X=\\mu+\\sigma Z$, then $x\\sim \\mathcal{N}(\\mu,\\sigma^2)$: $$\\mathcal{N}(\\mu,\\sigma^2)=\\mu+\\sigma Z$$\n",
    "    - Take a normal $X\\sim\\mathcal{N}(\\mu,\\sigma^2)$, make the random variable $Z=\\frac{X-\\mu}{\\sigma}$, then $Z\\sim \\mathcal{N}(0,1)$\n",
    "    - Take a normal $X\\sim\\mathcal{N}(\\mu,\\sigma^2)$, then $$P(X\\le x)=\\Phi\\left(\\frac{x-\\mu}{\\sigma}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e41dfc2",
   "metadata": {},
   "source": [
    "### Exponential and Laplace Distributions\n",
    "- In the context of deep learning, a probability distribution with a sharp point at $x=0$ is often wanted. **Exponential Distribution** can help to accomplish this.\n",
    "$$p(x|\\lambda)=\\lambda\\mathbf{1}_{x\\ge 0}\\mathrm{exp}(-\\lambda x)$$\n",
    "    - The indicator function $\\mathbf{1}_{x\\ge 0}$ is used to assign probability zero to all negative values of $x$\n",
    "- **Laplace distribution** allows us to place a sharp peak of probability mass at an arbitrary point $\\mu$\n",
    "$$\\mathrm{Laplace}(x|\\mu,\\gamma)=\\frac{1}{2\\gamma}\\mathrm{exp}\\left(-\\frac{|x-\\mu|}{\\gamma}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cde8f76",
   "metadata": {},
   "source": [
    "### Poisson Distribution\n",
    "- The *Poisson Distribution* is a very useful distribution that deal with the arrival of events. It measures probability of the number of events happening over a fixed period of time, given a fixed average rate of occurrence, and that the events take place independently of the time since the last event. It is parameterized by the average arrival rate $\\lambda$.$$P(X=k)=\\frac{\\mathrm{exp}(-\\lambda)\\lambda^{k}}{k!}$$\n",
    "- Expectation:\n",
    "    - $\\mathbb{E}[X]=\\lambda$\n",
    "- Variation:\n",
    "    - $\\mathbb{V}[X]=\\lambda$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7e535f",
   "metadata": {},
   "source": [
    "## Collections of Random Variables\n",
    "### Joint Distributions, Marginal Distributions and Conditional Distributions\n",
    "- **Joint Distributions**: Distributions over multiple random variables\n",
    "    - For discrete random variables $X$ and $Y$, the **joint probability mass function** of the pair $(X,Y)$ is the function $p(x,y)$ giving the probability that $X=x$ and $Y=y$ is denoted as:$$p(x,y)=P(X=x,Y=y)$$\n",
    "        - It's non-negative: $p(x,y)\\ge 0$\n",
    "        - Sum over all the possible values of all random variables is 1: $\\underset{x}{\\Sigma}\\underset{y}{\\Sigma}p(x,y)=1$\n",
    "        - *Sum Rule*: Marginalizing over the values of one of the random variables gets the PMF of the other: $\\underset{y}{\\Sigma}p(x,y)=p(x),\\underset{x}{\\Sigma}p(x,y)=p(y)$. This result is called the **Marginal Distribution**.\n",
    "    - For continuous random variables $X$ and $Y$, the **joint probability density function** of the pair $(X,Y)$ is the function $p(x,y)$ giving the probability that $X=x$ and $Y=y$:$$p(x,y)=\\underset{\\Delta x,\\Delta y\\rightarrow 0}{\\mathrm{lim}}\\frac{P(x\\le X\\le x+\\Delta x,y\\le Y \\le y+\\Delta y)}{\\Delta x\\Delta y}$$\n",
    "        - It's non-negative: $p(x,y)\\ge 0$\n",
    "        - Sum over all the possible values of all random variables is 1: $\\int\\int p(x,y)dxdy=1$\n",
    "        - *Sum Rule*: Marginalizing over the values of one of the random variables gets the PDF of the other:$\\int p(x,y)dy=p(x)$ and $\\int p(x,y)dx=p(y)$. The result is called the **Marginal Distribution**\n",
    "- **Conditional Distributions**: In many cases, the probability of some event given that some other event has happened is wanted. This called a **conditional probability**\n",
    "    - For random variables $X$ and $Y$, if $X=x$ is observed and the state of knowledge about $Y$ is need to be updated, then the conditional PDF is:$$P(Y=y|X=x)=p(y|x)=\\frac{P(X=x,Y=y)}{P(X=x)}=\\frac{p(x,y)}{p(x)}$$\n",
    "        - The conditional probability is only defined when $P(X=x)>0$. The conditional probability conditioned on an event that never happens is meaningless."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf8b505",
   "metadata": {},
   "source": [
    "### Chain Rule and Bayes Rule\n",
    "- **Chain Rule** / Product Rule of Conditional Probabilities $$P(x^{(1)},\\cdots,x^{(n)})=P(x^{(1)})\\underset{i=2}{\\overset{n}{\\Pi}}P(x^{i}|x^{(1)},\\cdots,x^{(i-1)})$$\n",
    "    - Often used to evaluate the joint probability of some random variables and is especially useful when there are (conditional) independence across variables\n",
    "    - Picking the right order to unravel the random variables can often make evaluating the probability much easier\n",
    "    - For example: $$\\begin{aligned}p(a,b,c)&=p(a|b,c)p(b,c)\\\\p(b,c)&=p(b|c)p(c)\\\\p(a,b,c)&=p(a|b,c)p(b|c)p(c)\\end{aligned}$$\n",
    "- **Bayes Rule** $$P(X|Y)=\\frac{P(Y|X)P(X)}{P(Y)}$$\n",
    "    - If $P(Y)$ is not given, we can always use the equation of calculating marginal probabilities first\n",
    "    - For example: $$\\begin{aligned}P(X,Y|Z)&=\\frac{P(Z|X,Y)P(X,Y)}{P(Z)}=\\frac{P(Y,Z|X)P(X)}{P(Z)}\\\\ P(X|Y,Z)&=\\frac{P(Y|X,Z)P(X,Z)}{P(Y,Z)}=\\frac{P(Y|X,Z)P(X|Z)P(Z)}{P(Y|Z)P(Z)}=\\frac{P(Y|X,Z)P(X|Z)}{P(Y|Z)}\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c09aa50",
   "metadata": {},
   "source": [
    "### Expectations\n",
    "- Take two random variables $X$ and $Y$ with joint PDF $p(x,y)$, the expectation of their sum is $$\\mathbb{E}[X+Y]=\\mathbb{E}[X]+\\mathbb{E}[Y]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd773ebc",
   "metadata": {},
   "source": [
    "### Correlated Random Variables\n",
    "- **Covariance**: A measure of the jointly variability of two random variables\n",
    "    - Gives some sense of how much two values are linearly related to each other\n",
    "    - For two jointly distributed random variables $X$ and $Y$, the covariance is defined as:$$\\mathbb{C}(X,Y)=\\mathbb{E}[(X-\\mathbb{E}[X])(Y-\\mathbb{E}[Y])]$$\n",
    "    - Correlation is not causation\n",
    "    - Two jointly distributed random variables $X$ and $Y$ is called:\n",
    "        - positively correlated if $\\mathbb{C}(X,Y)>0$\n",
    "        - negatively correlated if $\\mathbb{C}(X,Y)<0$\n",
    "        - uncorrelated if $\\mathbb{C}(X,Y)\\approx 0$\n",
    "- **Properties of the covariance**:\n",
    "    - Let $X$ be a random variable: $$\\mathbb{C}[X,X]=\\mathbb{V}[X]$$\n",
    "    - Let $X$ be a random variable and take any constant $\\lambda$: $$\\mathbb{C}[X,\\lambda]=0$$\n",
    "    - Let $X$ and $Y$ be two random variables: $$\\mathbb{C}[Y,X]=\\mathbb{C}[X,Y]$$\n",
    "    - Let $X$ and $Y$ be two random variables and take any constants: $$\\mathbb{C}[\\lambda X,\\mu Y]=\\lambda\\mu\\mathbb{C}[X,Y]$$\n",
    "    - Let $X$ and $Y$ be two random variables and take any constants: $$\\mathbb{C}[X+\\lambda,Y+\\mu]=\\mathbb{C}[X,Y]$$\n",
    "    - Let $X$, $Y$ and $Z$ be three random variables: $$\\mathbb{C}[X,Y+Z]=\\mathbb{C}[X,Y]+\\mathbb{C}[X,Z]$$\n",
    "    - Let $X$ and $Y$ be two random variable: $$\\mathbb{V}[X+Y]=\\mathbb{V}[X]+\\mathbb{V}[Y]+2\\mathbb{C}[X,Y]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344ceeb2",
   "metadata": {},
   "source": [
    "### Independent Random Variables\n",
    "- **Definition**: Two random variables $X$ and $Y$ are independent conditional on $I$, denoted as $X\\perp Y|I$ if and only if conditioning on one does not tell anything about the other $$p(x|y,I)=p(x|I)$$\n",
    "    - When there is no ambiguity, $I$ can be dropped\n",
    "- **Properties**: Assume $X$ and $Y$ are two independent random variables, then:\n",
    "    - $p(x,y)=p(x)p(y)$\n",
    "    - $\\mathbb{E}[XY]=\\mathbb{E}[X]\\mathbb{E}[Y]$\n",
    "    - $\\mathbb{C}[X,Y]=0$\n",
    "        - The reverse is not true. Uncorrelated variables do not have to be independent\n",
    "    - $\\mathbb{V}[X+Y]=\\mathbb{V}[X]+\\mathbb{V}[Y]$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cd16e1",
   "metadata": {},
   "source": [
    "## Random Vectors\n",
    "### Definition\n",
    "- A **list of random variables**, sometimes called **a multivariate random variable**\n",
    "- Let $X_1,X_2,\\cdots,X_N$ be $N$ random variables, then $\\mathbf{X}=\\left[X_1,X_2,\\cdots,X_N\\right]^T$ is called a **random vector**\n",
    "- The **joint probability density function** is denoted as $$p(\\mathbf{x})=p(x_1,\\cdots,x_N)$$ where $\\mathbf{x}=\\begin{bmatrix}x_1\\\\x_2\\\\ \\vdots\\\\ x_n \\end{bmatrix}$\n",
    "    - Properties:\n",
    "        - $\\forall \\mathbf{x},p(\\mathbf{x})\\ge 0$\n",
    "        - $\\int p(\\mathbf{x})dx_1dx_2\\cdots dx_N=1$\n",
    "        - $p(x_i)=\\int p(\\mathbf{x})dx_1\\cdots dx_{i-1}dx_{i+1}\\cdots dx_N$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df15adb",
   "metadata": {},
   "source": [
    "### Expectation and Covariance Matrix\n",
    "- **Expectation** of a random vector is the vector of expectation of *each component* $$\\mathbb{E}[\\mathbf{X}]=\\begin{bmatrix}\\mathbb{E}[X_1]\\\\ \\mathbb{E}[X_2]\\\\ \\vdots \\\\ \\mathbb{E}[X_N]\\end{bmatrix}$$\n",
    "- **Covariance Matrix**:\n",
    "    - Let $\\mathbf{X}$ be a $N$-dimensional random vector, $\\mathbf{Y}$ be an $M$-dimensional random vector, then the covariance of $\\mathbf{X}$ and $\\mathbf{Y}$ is the $N\\times M$ matrix consisting of all covariances between the components of $\\mathbf{X}$ and $\\mathbf{Y}$: $$\\mathbb{C}[\\mathbf{X},\\mathbf{Y}]=\\left[\\mathbb{C}[X_i,Y_j]\\right]_{i,j}$$\n",
    "    - We can easily show that: $$\\mathbb{C}[\\mathbf{X},\\mathbf{Y}]=\\mathbb{E}\\left[\\left(\\mathbf{X}-\\mathbb{E}\\left[\\mathbf{X}\\right]\\right)\\left(\\mathbf{Y}-\\mathbb{E}\\left[\\mathbf{Y}\\right]\\right)^T\\right]$$\n",
    "    - Self-covariance of $N$-dimensional random vector $\\mathbf{X}$ is a $N\\times N$ matrix: $$\\mathbb{C}[\\mathbf{X},\\mathbf{X}]=\\mathbb{E}\\left[\\left(\\mathbf{X}-\\mathbb{E}\\left[\\mathbf{X}\\right]\\right)\\left(\\mathbf{X}-\\mathbb{E}\\left[\\mathbf{X}\\right]\\right)^T\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ceeb8d1",
   "metadata": {},
   "source": [
    "### Multivariate Normal - Diagonal Covariance Case\n",
    "- Take the special case of $N$ **independent** random variables $X_1,...,X_N$ each distributed according to a normal with known mean and variance $$X_i=\\mathcal{N}(\\mu_i,\\sigma_i^2)$$ Then $\\mathbf{X}=\\left[X_1,\\cdots,X_N\\right]^T$ is called a **multivariate normal**\n",
    "- Expectation:\n",
    "    - $\\mathbb{E}[\\mathbf{X}]=\\begin{bmatrix}\\mathbb{E}[X_1]\\\\ \\mathbb{E}[X_2]\\\\ \\vdots \\\\ \\mathbb{E}[X_N]\\end{bmatrix}=\\begin{bmatrix}\\mu_1 \\\\ \\mu_2 \\\\ \\vdots \\\\ \\mu_N\\end{bmatrix}=\\pmb{\\mu}$\n",
    "- Covariance Matrix:\n",
    "    - Notice that the random variables are independent to each other, which means $$\\mathbb{C}[X_i,X_j]=\\left\\{\\begin{aligned}&0&i\\ne j\\\\&\\sigma_i^2&i=j\\end{aligned}\\right.$$\n",
    "    - Therefore, the covariance matrix of these matrix is $$\\mathbb{C}[\\mathbf{X},\\mathbf{X}]=\\begin{bmatrix}\\sigma_1^2&\\ &\\\\ \\ &\\ddots&\\ \\\\ &\\ &\\sigma_N^2\\end{bmatrix}=\\mathrm{diag}(\\sigma_1^2,\\sigma_2^2,\\cdots,\\sigma_N^2)=\\pmb{\\Sigma}$$\n",
    "- For a multivariate normal with mean vector $\\pmb{\\mu}$ and covariance matrix $\\pmb{\\Sigma}$, the notation is $$\\mathbf{X}\\sim\\mathcal{N}(\\pmb{\\mu},\\pmb{\\Sigma})$$\n",
    "where $$\\pmb{\\mu}=\\begin{bmatrix}\\mu_1 \\\\ \\mu_2 \\\\ \\vdots \\\\ \\mu_N\\end{bmatrix},\\pmb{\\Sigma}=\\begin{bmatrix}\\sigma_1^2&\\ &\\\\ \\ &\\ddots&\\ \\\\ &\\ &\\sigma_N^2\\end{bmatrix}$$\n",
    "- Joint probability density function:$$\\mathcal{N}(\\mathbf{x}|\\pmb{\\mu},\\pmb{\\Sigma})=\\sqrt{\\frac{1}{(2\\pi)^n\\mathrm{det}(\\pmb{\\Sigma})}}\\mathrm{exp}\\left(-\\frac{1}{2}(\\mathbf{x}-\\pmb{\\mu})^T\\pmb{\\Sigma}^{-1}(\\mathbf{x}-\\pmb{\\mu})\\right)$$\n",
    "- Connection to the standard normal\n",
    "    - Let $\\mathbf{Z}\\sim \\mathcal{N}(0,\\mathbf{I})$ be a collection of independent standard normal random variables $$Z_i\\sim\\mathcal{N}(0,1)$$ Define the random vector $$\\mathbf{X}=\\pmb{\\mu}+\\pmb{\\Sigma}\\mathbf{Z}$$ Then $$\\mathbf{X}\\sim \\mathcal{N}(\\pmb{\\mu},\\pmb{\\Sigma})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977aad51",
   "metadata": {},
   "source": [
    "### Multivariate Normal - Full Covariance Case\n",
    "- General case of $N$ random variables $X_1,...,X_N$ each distributed according to a normal with known mean and variance $$X_i=\\mathcal{N}(\\mu_i,\\sigma_i^2)$$ The random vector $\\mathbf{X}=\\left[X_1,\\cdots,X_N\\right]^T$ is denoted by $$\\mathbf{X}\\sim\\mathcal{N}(\\pmb{\\mu},\\pmb{\\Sigma})$$\n",
    "- **Restriction of the covariance matrix**\n",
    "    - In this general case, $\\pmb{\\Sigma}$ is no longer a diagonal matrix\n",
    "    - The covariance matrix has to be **positive definite**\n",
    "        - For any $\\mathbf{v}\\ne 0$, $\\mathbf{v}^T\\pmb{\\Sigma}\\mathbf{v}\\ge 0$\n",
    "        - This is so that $p(\\mathbf{x})$ has a global maximum\n",
    "        - Equivalently, $\\pmb{\\Sigma}$ must have positive eigenvalues\n",
    "- Connection to the standard normal\n",
    "    - Let $\\mathbf{Z}\\sim\\mathcal{N}(\\mathbf{0},\\mathbf{I})$ be a collection of independent standard normal random variables $$Z_i\\sim\\mathcal{N}(0,1)$$ Define the random vector $$\\mathbf{X}=\\pmb{\\mu}+\\mathbf{AZ}$$ Then $$\\mathbf{X}\\sim\\mathcal{N}(\\pmb{\\mu},\\mathbf{AA}^T)$$\n",
    "- **Marginalization**\n",
    "    - Let $\\mathbf{X}$ be a random vector made out of two random vectors $\\mathbf{X}_1$ and $\\mathbf{X}_2$:$$\\mathbf{X}=\\begin{bmatrix}\\mathbf{X}_1\\\\ \\mathbf{X}_2\\end{bmatrix}$$ Assume that$$\\mathbf{X}\\sim\\mathcal{N}(\\pmb{\\mu},\\pmb{\\Sigma})$$ Decompose mean and covariance in blocks: $$\\pmb{\\mu}=\\begin{bmatrix}\\pmb{\\mu}_1\\\\ \\pmb{\\mu}_2\\end{bmatrix},\\ \\pmb{\\Sigma}=\\begin{bmatrix}\\pmb{\\Sigma}_{1,1}&\\pmb{\\Sigma}_{1,2}\\\\ \\pmb{\\Sigma}_{1,2}^T&\\pmb{\\Sigma}_{2,2}\\end{bmatrix}$$ To find the probability density of $\\mathbf{X}_1$, marginalize $$p(\\mathbf{x}_1)=\\int p(\\mathbf{x}_1,\\mathbf{x}_2)d\\mathbf{x}_2=\\mathcal{N}(\\mathbf{x}_1|\\pmb{\\mu},\\pmb{\\Sigma}_{1,1})$$\n",
    "- **Conditioning**\n",
    "    - Let $\\mathbf{X}$ be a random vector made out of two random vectors $\\mathbf{X}_1$ and $\\mathbf{X}_2$:$$\\mathbf{X}=\\begin{bmatrix}\\mathbf{X}_1\\\\ \\mathbf{X}_2\\end{bmatrix}$$ Assume that $$\\mathbf{X}\\sim\\mathcal{N}(\\pmb{\\mu},\\pmb{\\Sigma}),\\ \\pmb{\\mu}=\\begin{bmatrix}\\pmb{\\mu}_1\\\\ \\pmb{\\mu}_2\\end{bmatrix},\\ \\pmb{\\Sigma}=\\begin{bmatrix}\\pmb{\\Sigma}_{1,1}&\\pmb{\\Sigma}_{1,2}\\\\ \\pmb{\\Sigma}_{1,2}^T&\\pmb{\\Sigma}_{2,2}\\end{bmatrix}$$ The conditional PDF is $$p(\\mathbf{x}_1|\\mathbf{x}_2)=\\frac{p(\\mathbf{x}_1,\\mathbf{x}_2)}{p(\\mathbf{x}_2)}\\propto p(\\mathbf{x}_1,\\mathbf{x}_2)=\\mathcal{N}(\\mathbf{x}_1|\\pmb{\\mu}_{1|\\mathbf{x}_2},\\pmb{\\Sigma}_{1,1|\\mathbf{x}_2})$$ Where $$\\pmb{\\mu}_{1|\\mathbf{x}_2}=\\pmb{\\mu}_1+\\pmb{\\Sigma}_{1,2}\\pmb{\\Sigma}_{2,2}^{-1}(\\mathbf{x}_2-\\pmb{\\mu}_2),\\ \\pmb{\\Sigma}_{1,1|\\mathbf{x}_2}=\\pmb{\\Sigma}_{1,1}-\\pmb{\\Sigma}_{1,2}\\pmb{\\Sigma}_{2,2}^{-1}\\pmb{\\Sigma}_{1,2}^T$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9710e22",
   "metadata": {},
   "source": [
    "# Sampling and Monte Carlo Method\n",
    "## Basic Sampling\n",
    "### Pseudo-random number generators\n",
    "- Computers are deterministic machines and they cannot generate completely random numbers\n",
    "- Pseudo-random number generator generates deterministic sequences of numbers that look random\n",
    "\n",
    "### Sample the uniform\n",
    "- Given\n",
    "    - PRNG's generate random integers from 0 to m\n",
    "- Procedure\n",
    "    - Sample a random integer $d$\n",
    "    - Set $x=\\frac{d}{m}$\n",
    "    - Calculate the **empirical CDF** ($\\hat{F}_N(x)$) with the ideal CDF $$\\hat{F}_N(x)=\\frac{\\mathrm{number \\ of\\ elements\\ in\\ sample\\le x}}{N}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33523de8",
   "metadata": {},
   "source": [
    "### Sample the categorical\n",
    "- To sample from a categorical distribution $$X\\sim \\mathrm{Categorical}(p_1,p_2,\\cdots,p_{k-1},1-\\mathbf{1}^T\\mathbf{p})$$\n",
    "    - Draw a uniform number $u\\sim U([0,1])$\n",
    "    - Find $j$ such that $$\\underset{k=0}{\\overset{j-1}{\\Sigma}}p_k\\le u\\lt\\underset{k=0}{\\overset{j}{\\Sigma}}p_k$$\n",
    "    - $j$-th state is the sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11990449",
   "metadata": {},
   "source": [
    "### Inverse Sampling\n",
    "- Let $X$ be an arbitrary univariate continuous random variable with CDF $F(x)$\n",
    "    - Draw a uniform number $u\\sim U([0,1])$\n",
    "    - Set $$x=F^{-1}(u)$$ and get the sample\n",
    "- Proof\n",
    "    - Let $U$ be a uniform random variable $$U\\sim U([0,1])$$ For any CDF $F(x)$ define the random variable $$X=F^{-1}(U)$$ The the CDF OF $X$ is $$\\begin{aligned}P(X\\le x)&=P(F^{-1}(U)\\le x)\\\\&=P(F(F^{-1}(U))\\le F(x))\\\\&=P(U\\le F(x))\\\\&=F_U(F(x))\\\\&=F(x)\\end{aligned}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e099b4a4",
   "metadata": {},
   "source": [
    "## The Monte Carlo Method for estimating expectations and variances\n",
    "### The uncertainty propagation problem\n",
    "- Given a random variable $X\\sim p(x)$ and a function $g(x)$, to quantify the uncertainty about the model output $Y=g(X)$\n",
    "    - $\\mathbb{E}[Y]=\\mathbb{E}[g(X)]=\\int g(x)p(x)$\n",
    "    - $\\mathbb{V}[Y]=\\int(g(x)-\\mathbb{E}[Y])^2p(x)dx=\\mathbb{E}[[g(x)]^2]-\\left(\\mathbb{E}[g(x)]\\right)^2$\n",
    "    - $P(Y\\ge y)=\\int \\mathbf{1}_{[y,\\infty]}(g(x))p(x)dx=\\mathbb{E}\\left[\\mathbf{1}_{[u,\\infty]}\\left(g(x)\\right)\\right]$\n",
    "- All the statistics are essentially expectations of functions of $X$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c3b299",
   "metadata": {},
   "source": [
    "### Curse of Dimensionality\n",
    "- The number of samples needed to estimate an arbitrary function with a given level of accuracy grows **exponentially** with respect to the number of input variables (i.e. dimensionality) of the function\n",
    "    - Take a $d$-dimensional uniform $X\\sim U([0,1]^d)$ and a function $g(x)$, to estimate $$\\mathbb{E}[g(X)]=\\int g(x)p(x)dx$$ use $n$ equidistance points per dimension, which results in $n^d$ boxes each with volume $n^{-d}$.  Evaluate the integral with $$\\mathbb{E}[g(x)]\\approx n^{-d}\\underset{j=1}{\\overset{n^d}{\\Sigma}}g\\left(x_j\\right)$$ and assume it takes a millisecond to evaluate the function $g(x)$ and n = 10, it takes\n",
    "        - 0.1 seconds when $d=1$\n",
    "        - 1 second when $d=2$\n",
    "        - 100 seconds when $d=3$\n",
    "        - 1000 seconds when $d=6$\n",
    "        - 115 days when $d=10$\n",
    "        - 3.17 billion years when $d=20$\n",
    "- **Blessing of dimensionality**\n",
    "    - Surprisingly and despite the expected \"curse of dimensionality\" difficulties, common-sense heuristics based on the most straightforward methods \"can yield results which are almost surely optimal\" for high-dimensional problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731a9ce0",
   "metadata": {},
   "source": [
    "### The law of large numbers\n",
    "- Take an infinite series of independent random variables $X_1,X_2,\\cdots$ with the same distribution (it doesn't matter what distribution), the sample average $$\\bar{X}_N=\\frac{1}{N}\\underset{i=1}{\\overset{N}{\\Sigma}}X_i\\rightarrow \\mu \\ \\mathrm{a.s.}$$ where $\\mathrm{a.s.}$ means \"almost surely\" and $\\mu=\\mathbb{E}[X_i]$ (as $N\\rightarrow \\infty$)\n",
    "- Take a random variable $X\\sim p(x)$ and some function $g(x)$, to estimate the **expectation**: $$I=\\mathbb{E}[g(X)]=\\int g(x)p(x)dx$$ Make independent identical copies of $X$:$$X_1,X_2,\\cdots\\sim p(x)$$ Consider the independent identical distribution: $$Y_1=g(X_1),Y_2=g(X_2),\\cdots$$ Then by the strong law of large numbers: $$I_N=\\frac{Y_1+Y_2+\\cdots+Y_N}{N}\\rightarrow \\mathbb{E}[Y_i]=\\mathbb{E}[g(X_i)]=I \\ \\mathrm{a.s.}$$\n",
    "- Take a random variable $X\\sim p(x)$ and some function $g(x)$, to estimate the **variance**: $$V=\\mathbb{V}[g(x)]=\\mathbb{E}\\left[\\left(g(X)-\\mathbb{E}[g(X)]\\right)^2\\right]=\\mathbb{E}\\left[\\left(g(X)-I\\right)^2\\right]=\\mathbb{E}\\left[g(x)^2\\right]-I^2$$ Take independent identical copies of $X$:$$X_1,X_2,\\cdots\\sim p(x)$$ Estimate the mean using a sample average: $$\\bar{I}_N=\\frac{1}{N}\\underset{i=1}{\\overset{N}{\\Sigma}}g(X_i)$$ Estimate the variance by: $$\\bar{V}_N=\\frac{1}{N}\\underset{i=1}{\\overset{N}{\\Sigma}}g^2(X_i)-\\bar{I}_N^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318d7b31",
   "metadata": {},
   "source": [
    "## Monte Carlo Estimates of various statistics\n",
    "### Estimating the cumulative distribution function\n",
    "- Take a random variable $X\\sim p(x)$ and some function $g(x)$, consider the derived random variable $Y=g(X)$, we would like to estimate the **cumulative distribution function**: $$F(y)=P(Y\\le y)=P(g(X)\\le y)$$\n",
    "- Consider the indicator function of a set $A$: $$1_{A}(y)=\\left\\{\\begin{aligned}&1 &y \\ \\mathrm{in}\\  A\\\\ &0&\\mathrm{otherwise}\\end{aligned}\\right.$$ Use it, we can write $F(y)$ as an expectation: $$F(y)=\\mathbb{E}\\left[1_{(-\\infty,y]}\\left(g(X)\\right)\\right]$$\n",
    "- Take $X_1,X_2,\\cdots$ independent identical copies of $X$\n",
    "- Estimate the CDF using a sample average: $$\\bar{F}_N(y)=\\frac{1}{N}\\underset{i=1}{\\overset{N}{\\Sigma}}1_{(-\\infty,y]}\\left(g(X_i)\\right)=\\frac{\\mathrm{number \\ of\\ }g(X_i)\\le y}{N}$$\n",
    "- This estimate is called the **empirical CDF**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b45f5c9",
   "metadata": {},
   "source": [
    "### Estimating the probability density function via histograms\n",
    "- Take a random variable $X\\sim p(x)$ and some function $g(x)$, consider the derived random variable $Y=g(X)$, we would like to estimate the **probability density function** $p(y)$ of $Y$\n",
    "- Take $M$ small bins $[b_0,b_1],\\cdots,[b_{M-1},b_M]$ in the $y$ space\n",
    "- Approximate $p(y)$ with a constant inside each bin: $$\\bar{p}_M(y)=\\underset{j=1}{\\overset{M}{\\Sigma}}c_j1_{[b_{j-1},b_j]}(y)$$ The constants $c_j$ are: $$c_j=P(b_{j-1}\\le Y\\le b_j)=F(b_j)-F(b_j-1)$$\n",
    "- So, we can approximate the constants $c_j$ with the empirical CDF: $$\\bar{c}_{j,N}=\\bar{F}_N(b_j)-\\bar{F}_N(b_{j-1})=\\frac{\\mathrm{number \\ of \\ samples\\ that\\ fall\\ in\\ bin\\ }[b_{j-1},b_j]}{N}\\rightarrow c_j \\ \\mathrm{a.s.}$$\n",
    "- Putting everything together the approximation becomes: $$\\bar{p}_{M,N}(y)=\\underset{j=1}{\\overset{M}{\\Sigma}}\\bar{c}_{j,N}1_{[b_{j-1},b_j]}(y)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ead105d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "304.475px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
