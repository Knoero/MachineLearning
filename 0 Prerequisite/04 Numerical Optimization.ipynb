{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbda3f5f",
   "metadata": {},
   "source": [
    "**Information:** *Brief introduction to convexity, optimization, and gradient descent*\n",
    "\n",
    "**Written by:** *Zihao Xu*\n",
    "\n",
    "**Last update date:** *05.29.2021*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdec5d92",
   "metadata": {},
   "source": [
    "# Convexity\n",
    "## Introduction\n",
    "- Convexity plays a vital rule in the design of optimization algorithms, which is largely due to fact that it is much easier to analyze and test algorithms in such a context. \n",
    "- If the algorithm performs poorly even in the convex setting, typically we should not hope to see great results otherwise.\n",
    "- Even though the optimization problems in ML/DL are generally non-convex, they often exhibit some properties of convex ones near local minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9370eac0",
   "metadata": {},
   "source": [
    "## Open and Closed Sets\n",
    "- Define $$A\\subset\\mathbb{R}^n$$ and open ball of diameter $\\epsilon$ is $B(r,\\epsilon)=\\{r\\in\\mathbb{R}^n:\\|r-r_o\\|<\\epsilon\\}$\n",
    "- A set $A$ is **open** if\n",
    "    - At every point, there is an open ball contained in $A$\n",
    "    - $\\forall r\\in A,\\ \\exists\\epsilon>0$ s.t. $B(r,\\epsilon)\\subset A$\n",
    "- A set $A$ is **closed** if $A^c=\\mathbb{R}^n-A$ is open\n",
    "- A set $A$ is compact if it is closed and bounded\n",
    "- Facts:\n",
    "    - $\\mathbb{R}^N$ is both open and closed, but it is not compact\n",
    "    - If $A$ is compact, then every sequence in $A$ has a limit point in $A$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743cf1c6",
   "metadata": {},
   "source": [
    "## Convex Sets\n",
    "### Definition\n",
    "- A set $C$ is convex if, for any $x,y\\in C$ and $\\theta\\in\\mathbb{R}$ with $0\\le\\theta\\le 1$: $$\\theta x+(1-\\theta)y\\in C$$\n",
    "    - Intuitively, it means if we take any two elements in $C$ and draw a line segment between these two elements, then every point on that line segment also belongs to $C$\n",
    "- The point $\\theta x+(1-\\theta)y$ is called a **convex combination** of the points $x$ and $y$\n",
    "\n",
    "### Examples\n",
    "- **All of** $\\mathbb{R}^n$. \n",
    "    - Given any $\\mathbf{x},\\mathbf{y}\\in\\mathbb{R}^n$,$$\\theta \\mathbf{x}+(1-\\theta)\\mathbf{y}\\in\\mathbb{R}^n$$\n",
    "- **The non-negative orthant** $\\mathbb{R}^n_+$.\n",
    "    - $\\mathbb{R}^n_+$ consists of all vectors in $\\mathbb{R}^n$ whose elements are all non-negative $$\\mathbb{R}^n_+=\\{\\mathbf{x}:x_i\\ge 0\\ \\forall i =1,\\cdots,n\\}$$\n",
    "    - Given any $\\mathbf{x},\\mathbf{y}\\in\\mathbb{R}^N_+$ and $0\\le\\theta\\le 1$, $$(\\theta \\mathbf{x}+(1-\\theta)\\mathbf{y})_i=\\theta x_i+(1-\\theta)y_i\\ge 0\\ \\forall i$$\n",
    "- **Norm balls**\n",
    "    - Let $\\|\\cdot\\|$ be some norm on $\\mathbb{R}^n$ (e.g., the Euclidean norm $\\|\\mathbf{x}\\|_2=\\sqrt{\\Sigma^n_{i=1}x_i^2}$). Then the set $\\{\\mathbf{x}:\\|\\mathbf{x}\\|\\le 1\\}$ is a convex set.\n",
    "    - Given $\\mathbf{x},\\mathbf{y}\\in\\mathbb{R}^n$ with $\\|\\mathbf{x}\\|\\le 1,\\|\\mathbf{y}\\|\\le 1$ and $0\\le\\theta\\le 1$. Then $$\\|\\theta \\mathbf{x}+(1-\\theta)\\mathbf{y}\\|\\le\\|\\theta \\mathbf{x}\\|+\\|(1-\\theta)\\mathbf{y}\\|=\\theta\\|\\mathbf{x}\\|+(1-\\theta)\\|\\mathbf{y}\\|\\le 1$$ where the **triangle inequality** and the **positive homogeneity** of norms are used\n",
    "- **Affine subspaces and polyhedra**\n",
    "    - Given a matrix $\\mathbf{A}\\in\\mathbb{R}^{m\\times n}$ and a vector $\\mathbf{b}\\in\\mathbb{R}^m$, an affine subspace is the set $\\{\\mathbf{x}\\in\\mathbb{R}^n:\\mathbf{A}\\mathbf{x}=\\mathbf{b}\\}$ (note this could possible be empty if $\\mathbf{b}$ is not in range of $\\mathbf{A}$).\n",
    "    - Given $\\mathbf{x},\\mathbf{y}\\in\\mathbb{R}^n$ s.t. $\\mathbf{Ax}=\\mathbf{Ay}=\\mathbf{b}$, then for $0\\le\\theta\\le 1$: $$\\mathbf{A}(\\theta \\mathbf{x}+(1-\\theta)\\mathbf{y})=\\theta \\mathbf{Ax}+(1-\\theta)\\mathbf{Ay}=\\theta \\mathbf{b}+(1-\\theta)\\mathbf{b}=\\mathbf{b}$$\n",
    "    - Similarly, a polyhedron is the set $\\{\\mathbf{x}\\in\\mathbb{R}^n:\\mathbf{Ax}\\preceq \\mathbf{b}\\}$ (also possibly empty), where $\\preceq$ denotes componentwise inequality\n",
    "        - All the entries of $\\mathbf{Ax}$ are less than or equal to their corresponding element in $\\mathbf{b}$\n",
    "    - Given $\\mathbf{x},\\mathbf{y}\\in\\mathbb{R}^n$ that satisfy $\\mathbf{Ax}\\le \\mathbf{b}$ and $\\mathbf{Ay}\\le \\mathbf{b}$ and $0\\le\\theta\\le 1$: $$\\mathbf{A}(\\theta \\mathbf{x}+(1-\\theta)\\mathbf{y})\\le\\theta \\mathbf{b}+(1-\\theta)\\mathbf{b}=\\mathbf{b}$$\n",
    "- **Intersection of convex sets**\n",
    "    - Suppose $C_1,C_2,\\cdots,C_k$ are convex sets. Then their intersection $$\\underset{i=1}{\\overset{k}{\\bigcap}}C_i=\\{x:x\\in C_i\\ \\forall i=1,\\cdots,k\\}$$ is also a convex set\n",
    "    - Given $x,y\\in\\underset{i=1}{\\overset{k}{\\bigcap}}C_i$ and $0\\le\\theta\\le 1$. Then $$\\theta x+(1-\\theta)y\\in C_i\\ \\forall i=1,\\cdots,k$$ by the definition of a convex set. Therefore $$\\theta x+(1-\\theta)y\\in\\underset{i=1}{\\overset{k}{\\bigcap}}C_i$$\n",
    "    - Note that the *union* of convex sets in general will not be convex\n",
    "- **Positive semidefinite matrices**\n",
    "    - The set of all symmetric positive semidefinite matrices, often times called the *positive semidefinite cone* and denoted $\\mathbb{S}_+^n$ is a convex set (in general, $\\mathbb{S}^n\\subset\\mathbb{R}^{n\\times n}$ denotes the set of symmetric $n\\times n$ matrices).\n",
    "    - A matrix $\\mathbf{A}\\in\\mathbb{R}^{n\\times n}$ is symmetric positive semidefinite if and only if $\\mathbf{A}=\\mathbf{A}^T$ and for all $\\mathbf{x}\\in\\mathbb{R}^n,\\mathbf{x}^T\\mathbf{Ax}\\le 0$\n",
    "    - Given two symmetric positive semidefinite matrices $\\mathbf{A},\\mathbf{B}\\in\\mathbb{S}^n_+$ and $0\\le\\theta\\le 1$, then for any $\\mathbf{x}\\in\\mathbb{R}^n$, $$\\mathbf{x}^T(\\theta\\mathbf{A}+(1-\\theta)\\mathbf{B})\\mathbf{x}=\\theta \\mathbf{x}^T\\mathbf{Ax}+(1-\\theta)\\mathbf{x}^T\\mathbf{B}\\mathbf{x}\\ge 0$$\n",
    "    - The logic to show that all **positive definite**, **negative definite**, and **negative semidefinite** matrices are each also convex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1801e5c0",
   "metadata": {},
   "source": [
    "## Convex Functions\n",
    "### Definition\n",
    "- A function $f:\\mathbb{R}^n\\rightarrow\\mathbb{R}$ is convex if its domain (denoted $\\mathcal{D}(f)$) is a *convex set*, and if, for all $\\mathbf{x},\\mathbf{y}\\in\\mathcal{D}(f)$ and $\\theta\\in\\mathbb{R},0\\le\\theta\\le 1$: $$f(\\theta\\mathbf{x}+(1-\\theta)\\mathbf{y})\\le\\theta f(\\mathbf{x})+(1-\\theta)f(\\mathbf{y})$$\n",
    "    - Intuitively, it means if we pick any two points on the graph pf a convex function and draw a straight line between them, then the portion of function between these two points will lie below this straight line.\n",
    "- A function is called **strictly convex** if the definition holds with strict inequality for $\\mathbf{x}\\ne\\mathbf{y}$ and $0\\lt\\theta\\lt 1$ \n",
    "- A function $f$ is called **concave** if $-f$ is convex\n",
    "- A function $f$ is called **strictly concave** if $-f$ is strictly convex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35631836",
   "metadata": {},
   "source": [
    "### First Order Condition for Convexity\n",
    "- Suppose a function $f:\\mathbb{R}^n\\rightarrow\\mathbb{R}$ is differentiable. Then $f$ is convex if and only if $\\mathcal{D}(f)$ is a convex set and for $\\mathbf{x},\\mathbf{y}\\in\\mathcal{D}(f)$, $$f(\\mathbf{y})\\ge f(\\mathbf{x})+\\nabla_x f(\\mathbf{x})^T(\\mathbf{y}-\\mathbf{x})$$ where the function $f(\\mathbf{x})+\\nabla_x f(\\mathbf{x})^T(\\mathbf{y}-\\mathbf{x})$ is called the **first-order approximation** to the function $f$ at the point $\\mathbf{x}$\n",
    "    - Intuitively, this can be thought of as approximating $f$ with its tangent line at the point $\\mathbf{x}$.\n",
    "- Similarly, $f$ would be \n",
    "    - strictly convex if this holds with strict inequality\n",
    "    - concave if the inequality is reversed\n",
    "    - strictly concave if the reverse inequality is strict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cb4e51",
   "metadata": {},
   "source": [
    "### Second Order Condition for Convexity\n",
    "- Suppose a function $f:\\mathbb{R}^n\\rightarrow\\mathbb{R}$ is twice differentiable. Then $f$ is convex if and only if $\\mathcal{D}(f)$ is a convex set and its *Hessian* is positive semidefinite: $$\\forall x\\in\\mathcal{D}(f),\\ \\nabla^2_xf(x)\\succeq 0$$\n",
    "    - Here the notation $\\succeq$ refers to positive semidefiniteness\n",
    "    - In one dimension, this is equivalent to the condition that the second derivative $f''(x)$ always be positive\n",
    "- Similarly, $f$ is\n",
    "    - strictly convex if its Hessian is positive definite\n",
    "    - concave if the Hessian is negative semidefinite\n",
    "    - strictly concave if the Hessian is negative definite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d2d551",
   "metadata": {},
   "source": [
    "### Jensen's Inequality\n",
    "- Start with the inequality in the basic definition of a convex function $$f(\\theta x+(1-\\theta)y)\\le\\theta f(x)+(1-\\theta)f(y)\\ \\text{for}\\ 0\\le\\theta\\le 1$$ Using induction, extend this definition to convex combinations of more than one point $$f\\left(\\underset{i=1}{\\overset{k}{\\Sigma}}\\theta_ix_i\\right)\\le\\underset{i=1}{\\overset{k}{\\Sigma}}\\theta_if(x_i)\\ \\ \\text{for}\\ \\underset{i=1}{\\overset{k}{\\Sigma}}\\theta_i=1,\\ \\theta_i\\ge 0\\ \\forall i$$ This can also extend to infinite sums or integrals. In the latter case, the inequality can be written as $$f\\left(\\int p(x)xdx\\right)\\le\\int p(x)f(x)dx \\ \\ \\ \\text{for}\\ \\ \\ \\int p(x)dx=1,\\ p(x)\\ge 0\\ \\ \\forall x$$ Since $\\int p(x)dx=1$, it is common to consider it a probability density, in which case the previous equation can be written in terms of expectations $$f(\\mathbb{E}[x])\\le\\mathbb{E}[f(x)]$$ which is called **Jensen's inequality**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0861fd28",
   "metadata": {},
   "source": [
    "### Examples\n",
    "- **Exponential**\n",
    "    - Let $f:\\mathbb{R}\\rightarrow\\mathbb{R},f(x)=e^{ax}$ for any $a\\in\\mathbb{R}$.\n",
    "    - $f''(x)=a^2e^{ax}$ is positive for all $x$\n",
    "- **Negative logarithm**\n",
    "    - Let $f:\\mathbb{R}\\rightarrow\\mathbb{R},f(x)=-\\text{log}x$ with domain $\\mathcal{D}(f)=\\mathbb{R}_{++}=\\{x:x>0\\}$\n",
    "    - $f''(x)=\\frac{1}{x^2}\\gt 0$ for all $x$\n",
    "- **Affine functions**\n",
    "    - Let $f:\\mathbb{R}^n\\rightarrow\\mathbb{R},f(\\mathbf{x})=\\mathbf{b}^T\\mathbf{x}+c$ for some $\\mathbf{b}\\in\\mathbb{R}^n,c\\in\\mathbb{R}$\n",
    "    - The Hessian $\\nabla^2_{\\mathbf{x}}f(\\mathbf{x})=0$ for all $\\mathbf{x}$\n",
    "    - Affine functions of this form are the **only** functions that are **both convex and concave**\n",
    "- **Quadratic function**\n",
    "    - Let $f:\\mathbb{R}^n\\rightarrow\\mathbb{R},f(\\mathbf{x})=\\frac{1}{2}\\mathbf{x}^T\\mathbf{Ax}+\\mathbf{b}^T\\mathbf{x}+c$ for a symmetric matrix $\\mathbf{A}\\in\\mathbb{S}^n,b\\in\\mathbb{R}^n$ and $c\\in\\mathbb{R}$\n",
    "    - The Hessian for this function is $\\nabla^2_{\\mathbf{x}}f(\\mathbf{x})=\\mathbf{A}$\n",
    "    - The convexity or non-convexity of $f$ is determined entirely by whether or not $\\mathbf{A}$ is positive semidefinite\n",
    "    - The **squared Euclidean norm** $f(\\mathbf{x})=\\|\\mathbf{x}\\|^2_2=\\mathbf{x}^T\\mathbf{x}$ is a special case of quadratic functions where $\\mathbf{A}=\\mathbf{I},\\mathbf{b}=\\mathbf{0},c=0$, so it is therefore a **strictly convex function**\n",
    "- **Norms**\n",
    "    - Let $f:\\mathbb{R}^n\\rightarrow\\mathbb{R}$ be some norm on $\\mathbb{R}^n$. \n",
    "    - By the **triangle inequality** and **positive homogeneity** of norms, for $\\mathbf{x},\\mathbf{y}\\in\\mathbb{R}^n,0\\le\\theta\\le 1$, $$f(\\theta \\mathbf{x}+(1-\\theta)\\mathbf{y})\\le f(\\theta \\mathbf{x})+f((1-\\theta)\\mathbf{y})=\\theta f(\\mathbf{x})+(1-\\theta)f(\\mathbf{y})$$\n",
    "    - Not possible to prove convexity based on the first or second order conditions because norms are not generally differentiable\n",
    "- **Nonnegative weighted sums of convex functions**\n",
    "    - Let $f_1,f_2,\\cdots,f_k$ be convex functions and $w_1,w_2,\\cdots,w_k$ be nonnegative real numbers. Then $$f(x)=\\underset{i=1}{\\overset{k}{\\Sigma}}w_if_i(x)$$ is a convex function, since $$\\begin{aligned}f(\\theta x+(1-\\theta)y)&=\\underset{i=1}{\\overset{k}{\\Sigma}}w_if_i(\\theta x+(1-\\theta)y)\\\\&\\le\\underset{i=1}{\\overset{k}{\\Sigma}}w_i(\\theta f_i(x)+(1-\\theta)f_i(y))\\\\&=\\theta\\underset{i=1}{\\overset{k}{\\Sigma}}w_if_i(x)+(1-\\theta)\\underset{i=1}{\\overset{k}{\\Sigma}}w_if_i(y)\\\\&=\\theta f(x)+(1-\\theta)f(x)\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b869b65",
   "metadata": {},
   "source": [
    "%%latex\n",
    "\\newpage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3358c1",
   "metadata": {},
   "source": [
    "# Optimization\n",
    "## Motivation\n",
    "- Most ML/DL algorithms involve **optimization** of some sort. \n",
    "    - Optimization refers to the task of either **minimizing** or maximizing some function $f(\\mathbf{x})$ by altering $\\mathbf{x}$\n",
    "    - Usually phrase most optimization problems in terms of minimizing $f(\\mathbf{x})$\n",
    "    - Maximization may be accomplished via s minimization algorithm by minimizing $-f(\\mathbf{x})$\n",
    "- Usually the function we want to minimize is called the **objective function**, or **criterion**. In ML/DL contexts, the name **loss function** is often used.\n",
    "    - As mentioned in introduction, a loss function quantifies the *distance* between the **real** and **predicted** value of the target.\n",
    "    - Usually be a non-negative number where smaller values are better and perfect predictions incur a loss of $0$\n",
    "    - Usually denoted as $L(\\boldsymbol{\\theta})$ where $\\boldsymbol{\\theta}$ is usually the parameter of ML/DL models \n",
    "- Usually denote the value that minimizes a function with a superscript $*$\n",
    "    - $\\boldsymbol{\\theta}^*=\\text{arg}\\underset{\\boldsymbol{\\theta}}{\\text{min}}L(\\boldsymbol{\\theta})$\n",
    "- Most ML/DL algorithms are so complex that it is difficult or impossible to find the closed form solution for the optimization problem\n",
    "    - Use numerical optimization method instead\n",
    "- One common algorithm is **gradient descent**, other optimization algorithms are\n",
    "    - Expectation Maximization\n",
    "    - Sampling-based optimization\n",
    "    - Greedy optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d94c2a",
   "metadata": {},
   "source": [
    "## Local Minimum and Global Minimum\n",
    "### Local Minimum\n",
    "- Let $f:A\\rightarrow\\mathbb{R}$ where $A\\subset \\mathbb{R}^N$, a point $x$ is locally minimal if it is available and if there exists some $R\\lt 0$ such that all feasible points $z$ with $\\|x-z\\|_2\\le R$, satisfy $f(x)\\le f(z)$\n",
    "- **Necessary** condition for local minimum\n",
    "    - Let $f$ be continuously differentiable and let $x\\in A$ be a local minimum, then $\\nabla f(x)=0$\n",
    "- **Saddle Point**:\n",
    "    - We say that $x\\in A$ is a saddle point of $f$ if $\\nabla f(x)=0$ and $r_o$ is not a local minimum\n",
    "\n",
    "### Global Minimum\n",
    "- A point $x$ is globally minimal if it is available and for all feasible points $z$, $f(x)\\le f(z)$\n",
    "    - A global minimum must also be a local minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a4f68d",
   "metadata": {},
   "source": [
    "## Optimization Theorems\n",
    "- Let $f:A\\rightarrow\\mathbb{R}$ where $A\\subset\\mathbb{R}^N$\n",
    "    - If $f$ is continuous and $A$ is **compact**, then $f$ takes on a global minimum in $A$\n",
    "    - If $f$ is **convex** on $A$, then any local minimum is a global minimum\n",
    "    - If $f$ is continuously differentiable and convex on $A$, then $\\nabla f(x)=0$ implies the $x\\in A$ is a global minimum of $f$\n",
    "- **Important Facts**:\n",
    "    - Global minimum **may not be unique**\n",
    "    - If $A$ is closed but not bounded, then $f$ may not take on a global minimum\n",
    "    - Most interesting functions in ML/DL are **not** convex "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea886f1",
   "metadata": {},
   "source": [
    "## Convex Optimization\n",
    "- Formally, a convex optimization problem is an optimization problem of the form $$\\begin{aligned}&\\text{minimize}&f(x)\\\\&\\text{subject to}&x\\in C\\end{aligned}$$ where $f$ is a convex function, $C$ is a convex set, and $x$ is the optimization variable\n",
    "- Often written as $$\\begin{aligned}&\\text{minimize}&f(x)&\\ \\\\&\\text{subject to}&g_i(x)\\le 0 &\\ \\ \\ i=1,\\cdots,m\\\\& &h_i(x)=0 &\\ \\ \\ i=1,\\cdots,p \\end{aligned}$$ where $f$ is a convex function, $g_i$ are convex functions and $h_i$ are affine functions and $x$ is the optimization variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588cc144",
   "metadata": {},
   "source": [
    "## Constrained Optimization\n",
    "### Definition\n",
    "- Sometimes we wish not only to maximize or minimize a function $f(\\mathbf{x})$ over all possible values of $\\mathbf{x}$. Instead the maximal or minimal value of $f(\\mathbf{x})$ for values of $\\mathbf{x}$ in some set $\\mathbb{S}$. This is known as **constrained optimization**\n",
    "- Points $\\mathbf{x}$ that lies within the set $\\mathbb{S}$ are called **feasible** points in constrained optimization terminology "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413eaf14",
   "metadata": {},
   "source": [
    "### Solution\n",
    "- **Intuition**: Design a different, **unconstrained** optimization problem whose solution can be converted into a solution to the original constrained optimization problem\n",
    "    - For example, to minimize $f(\\mathbf{x})$ for $\\mathbf{x}\\in\\mathbb{R}^2$ with $\\mathbf{x}$ constrained to have exactly unit $L^2$ norm, we can instead minimize $$g(\\theta)=f([\\text{cos}\\theta,\\text{sin}\\theta]^T)$$ with respect to $\\theta$, then return $[\\text{cos}\\theta,\\text{sin}\\theta]$ as the solution to the original problem\n",
    "    - Requires creativity\n",
    "    - The transformation between optimization problems must be designed specifically for each case we counter\n",
    "- **Karush-Kuhn-Tucker** (KKT) approach\n",
    "    - Provides a very general solution to constrained optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b654f48",
   "metadata": {},
   "source": [
    "%%latex\n",
    "\\newpage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648a47ef",
   "metadata": {},
   "source": [
    "# Gradient Descent\n",
    "## Basic Concepts\n",
    "### Definition\n",
    "- **Definition**:\n",
    "    - A **first-order iterative** optimization algorithm for finding **local minimum** of a **differential** function.\n",
    "        - The idea is to take *repeated steps* in the opposite direction of the *gradient* of the function at the current point, because this is the direction of steepest descent.\n",
    "        - As it only calculates the *first-order* derivative, it requires the objective function to be *differential* and is called *first-order optimization algorithms*\n",
    "            - Some optimization algorithms that also use the Hessian matrix are called *second-order optimization algorithms*\n",
    "        - Converge when first-order derivative is zero, which only ensures reaching **local minimum** for general functions\n",
    "            - That is to say, the start point will sometimes affect final convergence\n",
    "        - Generally speaking, gradient descent algorithms converge to the **global minimum** of continuously differentiable **convex** functions\n",
    "- **Theory**:\n",
    "    - Based on the observation that if the multi-variable function $F(\\mathbf{x})$ is defined and differentiable in a neighborhood of a point $\\mathbf{a}$, then $F(\\mathbf{x})$ decreases **fastest** if one goes from $\\mathbf{a}$ in the direction of the negative gradient of $F$ at $\\mathbf{a}$, which is $-\\nabla F(\\mathbf{a})$. It follows that if $$\\mathbf{a}_{n+1}=\\mathbf{a}_n-\\gamma\\nabla F(\\mathbf{a}_n)$$ for a $\\gamma\\in\\mathbb{R}_+$ small enough, then $$F(\\mathbf{a}_n)\\ge F(\\mathbf{a}_{n+1})$$\n",
    "- Simple form of **vanilla gradient descent** (GD):\n",
    "    1. Start at random parameter $\\boldsymbol{\\theta}$\n",
    "    2. Repeat until converged\n",
    "        - $\\mathbf{d}\\leftarrow-\\nabla L(\\boldsymbol{\\theta})$\n",
    "        - $\\boldsymbol{\\theta}\\leftarrow\\boldsymbol{\\theta}+\\alpha\\mathbf{d}^T$\n",
    "    - $\\alpha$ is called **learning rate** or **step size**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f957935",
   "metadata": {},
   "source": [
    "### Compute Loss Gradient\n",
    "- Take the **mean square error** as an example: $$\\begin{aligned}\\nabla_{\\boldsymbol{\\theta}}L_{MSE}(\\boldsymbol{\\theta})&=\\nabla_{\\boldsymbol{\\theta}}\\left\\{\\frac{1}{N}\\underset{i=1}{\\overset{N}{\\Sigma}}\\left\\|\\mathbf{y}_i-f_{\\boldsymbol{\\theta}}(\\mathbf{x}_i)\\right\\|^2\\right\\}\\\\&=\\frac{1}{N}\\underset{i=1}{\\overset{N}{\\Sigma}}\\nabla_{\\boldsymbol{\\theta}}\\left\\{(\\mathbf{y}_i-f_{\\boldsymbol{\\theta}}(\\mathbf{x}_i))^T(\\mathbf{y}_i-f_{\\boldsymbol{\\theta}}(\\mathbf{x}_i))\\right\\}\\end{aligned}$$ Use the chain rule and scale-by-vector matrix calculus identity that $$\\frac{\\partial \\mathbf{x}^T\\mathbf{x}}{\\partial \\mathbf{x}}=2\\mathbf{x}^T$$ We can get $$\\begin{aligned}\\nabla_{\\boldsymbol{\\theta}}L_{MSE}(\\boldsymbol{\\theta})&=\\frac{2}{N}\\underset{i=1}{\\overset{N}{\\Sigma}}(\\mathbf{y}_i-f_{\\boldsymbol{\\theta}}(\\mathbf{x}_i))^T\\nabla_{\\boldsymbol{\\theta}}(\\mathbf{y}_i-f_{\\boldsymbol{\\theta}}(\\mathbf{x}_i))\\\\&=\\frac{2}{N}\\underset{i=1}{\\overset{N}{\\Sigma}}(\\mathbf{y}_i-f_{\\boldsymbol{\\theta}}(\\mathbf{x}_i))^T\\nabla_{\\boldsymbol{\\theta}}(-f_{\\boldsymbol{\\theta}}(\\mathbf{x}_i))\\\\&=-\\frac{2}{N}\\underset{i=1}{\\overset{N}{\\Sigma}}(\\mathbf{y}_i-f_{\\boldsymbol{\\theta}}(\\mathbf{x}_i))^T\\nabla_{\\boldsymbol{\\theta}}(f_{\\boldsymbol{\\theta}}(\\mathbf{x}_i))\\end{aligned}$$\n",
    "- The result of the gradient usually includes three parts:\n",
    "    - Sum over training data. It consists of a lot of computations but the way of computation is relatively easy and straight forward\n",
    "    - Prediction error term such as $\\mathbf{y}_i-f_{\\boldsymbol{\\theta}}(\\mathbf{x}_i)$ in MSE, which is usually easy to get\n",
    "    - Gradient of inference function $\\nabla_{\\boldsymbol{\\theta}}(f_{\\boldsymbol{\\theta}}(\\mathbf{x}_i))$, which is difficult to solve\n",
    "        - Enabled by **automatic differentiation** built into modern domain specific languages such as Pytorch, Tensorflow, ...\n",
    "        - For neural networks, this is known as **back propagation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4cc8df",
   "metadata": {},
   "source": [
    "### Select appropriate learning rate\n",
    "- Too large $\\alpha$ leads to instability and even divergence\n",
    "- Too small $\\alpha$ leads to slow convergence\n",
    "- **Steepest gradient descent** use **line search** to compute the best $\\alpha$\n",
    "    1. Start at random parameter $\\boldsymbol{\\theta}$\n",
    "    2. Repeat until converged\n",
    "        - $\\mathbf{d}\\leftarrow-\\nabla L(\\boldsymbol{\\theta})$\n",
    "        - $\\alpha^*\\leftarrow\\text{arg}\\underset{\\alpha}{\\text{min}}\\{L(\\boldsymbol{\\theta}+\\alpha\\mathbf{d}^T)\\}$\n",
    "        - $\\boldsymbol{\\theta}\\leftarrow\\boldsymbol{\\theta}+\\alpha^*\\mathbf{d}^T$\n",
    "- **Adaptive learning rates** may help, but not always\n",
    "    - $\\alpha=\\frac{1}{t}$, approaches 0 but can cover an infinite distance since $\\underset{a\\rightarrow\\infty}{\\text{lim}}\\underset{t=1}{\\overset{a}{\\Sigma}}\\frac{1}{t}=\\infty$\n",
    "- **Coordinate Descent** update one parameter at a time\n",
    "    - Removes problem of selecting step size\n",
    "    - Each update can be very fast, but lots of updates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f85690",
   "metadata": {},
   "source": [
    "### Slow convergence due to Poor Conditioning\n",
    "- **Conditioning** refers to how rapidly a function changes with respect to small changes in its inputs.\n",
    "- Consider the function $$f(x)=\\mathbf{A}^{-1}\\mathbf{x}$$ When $\\mathbf{A}\\in\\mathbb{R}^{n\\times n}$ has an eigenvalue decomposition, its **condition number** is $$\\underset{i,j}{\\text{max}}\\left|\\frac{\\lambda_i}{\\lambda_j}\\right|$$ This is the ratio of the magnitude of the largest and smallest eigenvalue\n",
    "- A problem with a **low condition number** is said to be **well-conditioned**, while a problem with a high condition number is said to be ill-conditioned\n",
    "    - In non-mathematical terms, an ill-conditioned problem is one where, for a small change in the inputs there is a large change in the answer or dependent variable, which means the correct solution to the equation becomes hard to find\n",
    "    - Condition number is a property of the problem\n",
    "- **Gradient descent** is very sensitive to **condition number** of the problem\n",
    "    - No good choice of step size. Tiny change in one variable could lead to great change in dependent variable.\n",
    "- **Solutions:**\n",
    "    - **Newton's method:** Correct for local second derivative.\n",
    "        - Too much computation and too difficult to implement\n",
    "        - Harmful when near saddle points\n",
    "    - **Alternative methods**:\n",
    "        - Preconditioning: Easy, but tends to be ad-hoc, not so robust\n",
    "        - Momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cad9e44",
   "metadata": {},
   "source": [
    "### Vanishing Gradients\n",
    "- The most insidious problem to encounter\n",
    "- Some function leads to almost zero gradients far away from local minimums, which makes the optimization stuck for a long time or even stop.\n",
    "- For example, assume that we want to minimize the function $$f(x)=\\text{tanh}(x)$$ The derivative is $$f'(x)=1-\\text{tanh}^2(x)$$ If we happen to get started at $x=4$ then the derivative at that point is $$f'(4)=0.0013$$ The gradient is close to nil. Consequently, optimization will get stuck for a long time before we make progress\n",
    "- **Possible Solutions**:\n",
    "    - Reparameterize the problem\n",
    "    - Good initialization of the parameter\n",
    "    - Reconstruct the objective function (e.g., change activation function in neural networks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "304.475px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
