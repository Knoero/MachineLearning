{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbda3f5f",
   "metadata": {},
   "source": [
    "**Information:** *Brief introduction to gradient descent, how gradient descent is supported in pytorch, convex functions, and some numerical considerations to kept in mind*\n",
    "\n",
    "**Written by:** *Zihao Xu*\n",
    "\n",
    "**Last update date:** *05.28.2021*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb10525d",
   "metadata": {},
   "source": [
    "# Gradient Descent Optimization\n",
    "## Motivation\n",
    "- Most ML/DL algorithms involve **optimization** of some sort. \n",
    "    - Optimization refers to the task of either **minimizing** or maximizing some function $f(\\mathbf{x})$ by altering $\\mathbf{x}$\n",
    "    - Usually phrase most optimization problems in terms of minimizing $f(\\mathbf{x})$\n",
    "    - Maximization may be accomplished via s minimization algorithm by minimizing $-f(\\mathbf{x})$\n",
    "- Usually the function we want to minimize is called the **objective function**, or **criterion**. In ML/DL contexts, the name **loss function** is often used.\n",
    "    - As mentioned in introduction, a loss function quantifies the *distance* between the **real** and **predicted** value of the target.\n",
    "    - Usually be a non-negative number where smaller values are better and perfect predictions incur a loss of $0$\n",
    "    - Usually denoted as $L(\\boldsymbol{\\theta})$ where $\\boldsymbol{\\theta}$ is usually the parameter of ML/DL models \n",
    "- Usually denote the value that minimizes a function with a superscript $*$\n",
    "    - $\\boldsymbol{\\theta}^*=\\text{arg}\\underset{\\boldsymbol{\\theta}}{\\text{min}}L(\\boldsymbol{\\theta})$\n",
    "- Most ML/DL algorithms are so complex that it is difficult or impossible to find the closed form solution for the optimization problem\n",
    "    - Use numerical optimization method instead\n",
    "- One common algorithm is **gradient descent**, other optimization algorithms are\n",
    "    - Expectation Maximization\n",
    "    - Sampling-based optimization\n",
    "    - Greedy optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648a47ef",
   "metadata": {},
   "source": [
    "## Definition\n",
    "- **Definition**:\n",
    "    - A **first-order iterative** optimization algorithm for finding **local minimum** of a **differential** function.\n",
    "        - The idea is to take **repeated steps** in the opposite direction of the **gradient** of the function at the current point, because this is the direction of steepest descent.\n",
    "        - As it calculates the **first-order** derivative, it requires the objective function to be **differential**\n",
    "        - Converge when first-order derivative is zero, which only ensures reaching **local minimum** for general functions\n",
    "- **Theory**:\n",
    "    - Based on the observation that if the multi-variable function $F(\\mathbf{x})$ is defined and differentiable in a neighborhood of a point $\\mathbf{a}$, then $F(\\mathbf{x})$ decreases **fastest** if one goes from $\\mathbf{a}$ in the direction of the negative gradient of $F$ at $\\mathbf{a}$, which is $-\\nabla F(\\mathbf{a})$. It follows that if $$\\mathbf{a}_{n+1}=\\mathbf{a}_n-\\gamma\\nabla F(\\mathbf{a}_n)$$ for a $\\gamma\\in\\mathbb{R}_+$ small enough, then $$F(\\mathbf{a}_n)\\ge F(\\mathbf{a}_{n+1})$$\n",
    "- Simple form of **vanilla gradient descent** (GD):\n",
    "    1. Start at random parameter $\\boldsymbol{\\theta}$\n",
    "    2. Repeat until converged\n",
    "        - $\\mathbf{d}\\leftarrow-\\nabla L(\\boldsymbol{\\theta})$\n",
    "        - $\\boldsymbol{\\theta}\\leftarrow\\boldsymbol{\\theta}+\\alpha\\mathbf{d}^T$\n",
    "    - $\\alpha$ is called **learning rate** or **step size**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4cc8df",
   "metadata": {},
   "source": [
    "## Select appropriate learning rate\n",
    "- Too large $\\alpha$ leads to instability and even divergence\n",
    "- Too small $\\alpha$ leads to slow convergence\n",
    "- **Steepest gradient descent** use line search to compute the best $\\alpha$\n",
    "    1. Start at random parameter $\\boldsymbol{\\theta}$\n",
    "    2. Repeat until converged\n",
    "        - $\\mathbf{d}\\leftarrow-\\nabla L(\\boldsymbol{\\theta})$\n",
    "        - $\\alpha^*\\leftarrow\\text{arg}\\underset{\\alpha}{\\text{min}}\\{L(\\boldsymbol{\\theta}+\\alpha\\mathbf{d}^T)\\}$\n",
    "        - $\\boldsymbol{\\theta}\\leftarrow\\boldsymbol{\\theta}+\\alpha^*\\mathbf{d}^T$\n",
    "- **Adaptive learning rates** may help, but not always\n",
    "    - $\\alpha=\\frac{1}{t}$, approaches 0 but can cover an infinite distance since $\\underset{a\\rightarrow\\infty}{\\text{lim}}\\underset{t=1}{\\overset{a}{\\Sigma}}\\frac{1}{t}=\\infty$\n",
    "- **Coordinate Descent** update one parameter at a time\n",
    "    - Removes problem of selecting step size\n",
    "    - Each update can be very fast, but lots of updates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f85690",
   "metadata": {},
   "source": [
    "## Slow convergence due to Poor Conditioning\n",
    "- **Conditioning** refers to how rapidly a function changes with respect to small changes in its inputs.\n",
    "- Consider the function $$f(x)=\\mathbf{A}^{-1}\\mathbf{x}$$ When $\\mathbf{A}\\in\\mathbb{R}^{n\\times n}$ has an eigenvalue decomposition, its **condition number** is $$\\underset{i,j}{\\text{max}}\\left|\\frac{\\lambda_i}{\\lambda_j}\\right|$$ This is the ratio of the magnitude of the largest and smallest eigenvalue\n",
    "- A problem with a **low condition number** is said to be **well-conditioned**, while a problem with a high condition number is said to be ill-conditioned\n",
    "    - In non-mathematical terms, an ill-conditioned problem is one where, for a small change in the inputs there is a large change in the answer or dependent variable, which means the correct solution to the equation becomes hard to find\n",
    "    - Condition number is a property of the problem\n",
    "- **Gradient descent** is very sensitive to **condition number** of the problem\n",
    "    - No good choice of step size. Tiny change in one variable could lead to great change in dependent variable.\n",
    "- **Solutions:**\n",
    "    - **Newton's method:** Correct for local second derivative. (Sphere the ellipse)\n",
    "        - Too much computation and too difficult to implement\n",
    "    - **Alternative methods**:\n",
    "        - Preconditioning: Easy, but tends to be ad-hoc, not so robust\n",
    "        - Momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef995704",
   "metadata": {},
   "source": [
    "## Compute Loss Gradient\n",
    "- Take the **mean square error** as an example: $$\\begin{aligned}\\nabla_{\\boldsymbol{\\theta}}L_{MSE}(\\boldsymbol{\\theta})&=\\nabla_{\\boldsymbol{\\theta}}\\left\\{\\frac{1}{N}\\underset{i=1}{\\overset{N}{\\Sigma}}\\left\\|\\mathbf{y}_i-f_{\\boldsymbol{\\theta}}(\\mathbf{x}_i)\\right\\|^2\\right\\}\\\\&=\\frac{1}{N}\\underset{i=1}{\\overset{N}{\\Sigma}}\\nabla_{\\boldsymbol{\\theta}}\\left\\{(\\mathbf{y}_i-f_{\\boldsymbol{\\theta}}(\\mathbf{x}_i))^T(\\mathbf{y}_i-f_{\\boldsymbol{\\theta}}(\\mathbf{x}_i))\\right\\}\\end{aligned}$$ Use the chain rule and scale-by-vector matrix calculus identity that $$\\frac{\\partial \\mathbf{x}^T\\mathbf{x}}{\\partial \\mathbf{x}}=2\\mathbf{x}^T$$ We can get $$\\begin{aligned}\\nabla_{\\boldsymbol{\\theta}}L_{MSE}(\\boldsymbol{\\theta})&=\\frac{2}{N}\\underset{i=1}{\\overset{N}{\\Sigma}}(\\mathbf{y}_i-f_{\\boldsymbol{\\theta}}(\\mathbf{x}_i))^T\\nabla_{\\boldsymbol{\\theta}}(\\mathbf{y}_i-f_{\\boldsymbol{\\theta}}(\\mathbf{x}_i))\\\\&=\\frac{2}{N}\\underset{i=1}{\\overset{N}{\\Sigma}}(\\mathbf{y}_i-f_{\\boldsymbol{\\theta}}(\\mathbf{x}_i))^T\\nabla_{\\boldsymbol{\\theta}}(-f_{\\boldsymbol{\\theta}}(\\mathbf{x}_i))\\\\&=-\\frac{2}{N}\\underset{i=1}{\\overset{N}{\\Sigma}}(\\mathbf{y}_i-f_{\\boldsymbol{\\theta}}(\\mathbf{x}_i))^T\\nabla_{\\boldsymbol{\\theta}}(f_{\\boldsymbol{\\theta}}(\\mathbf{x}_i))\\end{aligned}$$\n",
    "- The result of the gradient usually includes three parts:\n",
    "    - Sum over training data. It consists of a lot of computations but the way of computation is relatively easy and straight forward\n",
    "    - Prediction error term such as $\\mathbf{y}_i-f_{\\boldsymbol{\\theta}}(\\mathbf{x}_i)$ in MSE, which is usually easy to get\n",
    "    - Gradient of inference function $\\nabla_{\\boldsymbol{\\theta}}(f_{\\boldsymbol{\\theta}}(\\mathbf{x}_i))$, which is difficult to solve\n",
    "        - Enabled by automatic differentiation built into modern domain specific languages such as Pytorch, Tensorflow, ...\n",
    "        - For neural networks, this is known as **back propagation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cb2106",
   "metadata": {},
   "source": [
    "%%latex\n",
    "\\newpage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b666ed1",
   "metadata": {},
   "source": [
    "# Automatic Differentiation via Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d48f00",
   "metadata": {},
   "source": [
    "## Data Manipulation via Pytorch\n",
    "- The $n$-dimensional array is usually called the tensor\n",
    "- *tensor* class in Pytorch is similar to *NumPy*'s *ndarray* with several additional features\n",
    "    - GPU is well-supported to accelerate the computation whereas *NumPy* only supports CPU computation\n",
    "    - *tensor* class supports automatic differentiation\n",
    "- The [Pytorch documentation](https://pytorch.org/docs/master/torch.html) shows the full attributes\n",
    "\n",
    "### Create a tensor\n",
    "- To get started, import **torch**. Although it's called Pytorch, we should import **torch** instead of pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6259cd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Check the version of a module\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b14069",
   "metadata": {},
   "source": [
    "- Common ways to creating a tensor\n",
    "    - torch.arange(start,end,step)\n",
    "    - torch.zeros(shape)\n",
    "    - torch.ones(shape)\n",
    "    - torch.randn(shape)\n",
    "    - torch.tensor(elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42d89ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0, 12, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87a5abbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros((3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6df5fdde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones((2, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06a71d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.4958,  0.2206, -0.3878, -0.4165,  0.2741, -0.1352,  0.8250, -0.3746,\n",
       "        -0.8352, -1.5164])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d81ac76c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[1, 2, 3], [4, 5, 6]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b91ff2",
   "metadata": {},
   "source": [
    "- One can access a tensor's shape by viewing the **shape** attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "204807d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 5])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones((4, 5)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8a8afd",
   "metadata": {},
   "source": [
    "- **reshape** method can change the shape of a tensor without altering either the number of elements or their values.\n",
    "    - No need to manually specify every dimension\n",
    "    - Can place $-1$ for the dimension that we would like tensors to automatically infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb2c4e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(12).reshape(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87c0bcb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(12).reshape(3, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a086d1d8",
   "metadata": {},
   "source": [
    "### Type of a tensor\n",
    "- Usually, a tensor is created as **tensor.float32** (32-bit floating point) by default. One can view its type in the **dtype** attribute\n",
    "    - When creating a tensor using **torch.tensor**, tensor with all integers would be created as **torch.int64** (64-bit signed integer)\n",
    "- Full tensor types can be viewed in the [documentation](https://pytorch.org/docs/master/tensor_attributes.html#torch.torch.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d4116bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(10).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49c769c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[1, 2, 3], [4, 5, 6]]).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b81d2c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only add one dot after the first element\n",
    "torch.tensor([[1., 2, 3], [4, 5, 6]]).dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9147c6c0",
   "metadata": {},
   "source": [
    "- One can assign the wanted type when creating the tensor by setting the **dtype** attribute to\n",
    "    - *torch.float32*, 32-bit floating point\n",
    "    - *torch.float64*, 64-bit floating point\n",
    "    - *torch.uint8*, 8-bit unsigned integer\n",
    "    - *torch.int8*, 8-bit signed integer\n",
    "    - *torch.int32*, 32-bit signed integer\n",
    "    - *torch.int64*, 64-bit signed integer\n",
    "    - *torch.bool*, Boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed180e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(10, dtype=torch.float64).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fbd2cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.uint8"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(10, dtype=torch.uint8).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b340cf6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int32"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(10, dtype=torch.int32).dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5e003f",
   "metadata": {},
   "source": [
    "- One can also construct the type of a tensor from list or numpy array using the method:\n",
    "    - *FloatTensor*, 32-bit floating point\n",
    "    - *DoubleTensor*, 64-bit floating point\n",
    "    - *ByteTensor*, 8-bit unsigned integer\n",
    "    - *CharTensor*, 8-bit signed integer\n",
    "    - *IntTensor*, 32-bit signed integer\n",
    "    - *LongTensor*, 64-bit signed integer\n",
    "    - *BoolTensor*, Boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "985d92aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.DoubleTensor([1, 2, 3]).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d2c0c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.uint8"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ByteTensor([1, 2, 3]).dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25840892",
   "metadata": {},
   "source": [
    "### Use GPU for tensor computation\n",
    "- Unless otherwise specified, a new tensor will be stored in main memory and designated for CPU-based computation\n",
    "- One can check which device the tensor is designated for by viewing the **device** attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7452789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(10).device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926607cd",
   "metadata": {},
   "source": [
    "- One can always set the create a device if a GPU supporting cuda is available and use **to(device)** method to determine the device on which a tensor is or will be allocated\n",
    "    - Assign the **device** parameter when creating a tensor also works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8591020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda0 = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "cuda0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e73747b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1.], device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(5, device=cuda0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da6418fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1.], device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If available, indexing the cuda also works\n",
    "torch.ones(5, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ca14f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1.], device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If avaiable, the string also works\n",
    "torch.ones(5, device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b9cbe64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1.], device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the to method the move a tensor\n",
    "x = torch.ones(5).to(cuda0)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f1a5124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One can also move a tensor from GPU to CPU\n",
    "x.to(\"cpu\").device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3b9ec2",
   "metadata": {},
   "source": [
    "### Operations\n",
    "- Common standard arithmetic operators have all been lifted to element-wise operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e3cf31b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2., 3., 5., 9.]), tensor([1., 2., 4., 8.]), tensor([1., 2., 4., 8.]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1., 2., 4., 8.])\n",
    "c = 1.\n",
    "x + c, x * c, x**c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d3f7680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([5., 5., 6., 9.]),\n",
       " tensor([4., 6., 8., 8.]),\n",
       " tensor([ 1.,  8., 16.,  8.]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1., 2., 4., 8.])\n",
    "y = torch.tensor([4., 3., 2., 1.])\n",
    "x + y, x * y, x**y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5eadd29a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.7183e+00, 7.3891e+00, 5.4598e+01, 2.9810e+03])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7dc9f9",
   "metadata": {},
   "source": [
    "- Matrix multiplication is also supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "440c426e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 3.4776, -1.6009, -0.0927, -3.0731, -1.6719],\n",
       "         [-2.5072,  1.3272, -0.5220,  0.5175,  1.5722],\n",
       "         [ 0.9626, -0.3774,  0.2813,  0.3111, -0.5749],\n",
       "         [ 1.0100,  1.6795, -1.0543, -0.5897,  1.0897]]),\n",
       " tensor([[ 3.4776, -1.6009, -0.0927, -3.0731, -1.6719],\n",
       "         [-2.5072,  1.3272, -0.5220,  0.5175,  1.5722],\n",
       "         [ 0.9626, -0.3774,  0.2813,  0.3111, -0.5749],\n",
       "         [ 1.0100,  1.6795, -1.0543, -0.5897,  1.0897]]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.randn((4, 3))\n",
    "B = torch.randn((3, 5))\n",
    "# Two ways of matrix multiplication\n",
    "torch.mm(A, B), A @ B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4eacb01c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 2.7632e-01, -2.8037e-01,  1.3489e-01,  8.0120e-02],\n",
       "         [-2.8262e-01,  5.2607e-01, -6.7521e-03,  1.0018e+00],\n",
       "         [ 4.8200e-02,  1.9570e+00, -2.8883e-03, -1.2611e-01],\n",
       "         [-4.6326e-01,  2.0817e+00, -2.9168e+00,  7.9631e-02],\n",
       "         [-3.0559e+00,  4.7762e-01, -5.6648e-01, -4.0203e-02]]),\n",
       " tensor([[ 2.7632e-01, -2.8037e-01,  1.3489e-01,  8.0120e-02],\n",
       "         [-2.8262e-01,  5.2607e-01, -6.7521e-03,  1.0018e+00],\n",
       "         [ 4.8200e-02,  1.9570e+00, -2.8883e-03, -1.2611e-01],\n",
       "         [-4.6326e-01,  2.0817e+00, -2.9168e+00,  7.9631e-02],\n",
       "         [-3.0559e+00,  4.7762e-01, -5.6648e-01, -4.0203e-02]]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.randn((5, 4))\n",
    "B = torch.randn((5, 4))\n",
    "# Two ways of elementwise multiplication\n",
    "torch.mul(A, B), A * B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4c8c8c",
   "metadata": {},
   "source": [
    "- We can also **concatenate** multiple tensors together, stacking them end-to-end to form a larger tensor. We just need to provide a list of tensors and tell the system along which axis to concatenate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "093d0b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [ 1.,  1.,  1.,  1.],\n",
       "         [ 1.,  1.,  1.,  1.],\n",
       "         [ 1.,  1.,  1.,  1.]]),\n",
       " tensor([[ 0.,  1.,  2.,  3.,  1.,  1.,  1.,  1.],\n",
       "         [ 4.,  5.,  6.,  7.,  1.,  1.,  1.,  1.],\n",
       "         [ 8.,  9., 10., 11.,  1.,  1.,  1.,  1.]]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(0, 12, 1).reshape((3, 4))\n",
    "B = torch.ones((3, 4))\n",
    "# dim stands for the index of dimension in which the tensors are concatenated\n",
    "torch.cat((A, B), dim=0), torch.cat((A, B), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74edfa6",
   "metadata": {},
   "source": [
    "- Also, we can construct a binary tensor via logical statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "796ece79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[False, False, False, False],\n",
       "         [False,  True, False, False],\n",
       "         [False, False, False, False]]),\n",
       " tensor([[False, False, False, False],\n",
       "         [False, False,  True,  True],\n",
       "         [ True,  True,  True,  True]]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(0, 12, 1).reshape((3, 4))\n",
    "B = 5 * torch.ones((3, 4))\n",
    "A == B, A > B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c855c15d",
   "metadata": {},
   "source": [
    "### Broadcasting Mechanism\n",
    "- Under certain conditions, even shapes differ, we can still perform **element-wise** operations by invoking the **broadcasting mechanism**.\n",
    "    - First, expand one or both arrays by copying elements appropriately so that after this transformation, the two tensors have the same shape.\n",
    "    - Second, carry out the element-wise operation on the resulting arrays\n",
    "- In most cases, we broadcast along an axis where an array initially only has length 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "855266ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0],\n",
       "         [1],\n",
       "         [2]]),\n",
       " tensor([[0, 1]]),\n",
       " tensor([[0, 1],\n",
       "         [1, 2],\n",
       "         [2, 3]]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(3).reshape(3, 1)\n",
    "b = torch.arange(2).reshape(1, 2)\n",
    "a, b, a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcc4c6c",
   "metadata": {},
   "source": [
    "### Indexing and Slicing\n",
    "- As in standard Python lists, we can access elements according to their relative position to the end of the list by using negative indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "156988a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11],\n",
       "         [12, 13, 14, 15]]),\n",
       " tensor([12, 13, 14, 15]),\n",
       " tensor([[ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(16).reshape(4, 4)\n",
    "X, X[-1], X[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37e5d1a",
   "metadata": {},
   "source": [
    "- Can also index using binary tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cda5b65f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]]),\n",
       " tensor([[5., 5., 5., 5.],\n",
       "         [5., 5., 5., 5.],\n",
       "         [5., 5., 5., 5.]]),\n",
       " tensor([ 6,  7,  8,  9, 10, 11]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(0, 12, 1).reshape((3, 4))\n",
    "B = 5 * torch.ones((3, 4))\n",
    "A, B, A[A > B]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3cd585",
   "metadata": {},
   "source": [
    "## Automatic Calculation of Gradients\n",
    "- In practice, based on our designed model, the system builds a **computational graph**, tracking which data combined through which operations to produce the output. Automatic differentiation enables the system to subsequently **backpropagate gradients**.\n",
    "    - Here *backpropagate* simply means to trace through the computational graph, filling in the partial derivatives with respect to each parameter\n",
    "\n",
    "### Intuition\n",
    "- All computation can be broken into simple components\n",
    "    - sum\n",
    "    - multiply\n",
    "    - exponential\n",
    "    - convolution\n",
    "    - ...\n",
    "- Derivatives for each simple component can be derived mathematically\n",
    "- Derivatives for **any composition** can be derived via **chain rule**\n",
    "- That is to say, for a function $$f=f(x_1,x_2,\\cdots,x_n)$$ Start from the chain rule $$\\frac{\\partial f}{\\partial t}=\\underset{j=1}{\\overset{n}{\\Sigma}}\\frac{\\partial f}{\\partial x_j}\\frac{\\partial x_j}{\\partial t}$$ And decompose $f$ into simple components such as $$f=g_1(g_2(\\cdots g_M(x_1,x_2,\\cdots,x_n)))$$ Where all the functions $g(\\bullet)$ are simple components like sum, multiplication ..., we can always get the derivative respect to time $$\\frac{\\partial f}{\\partial t}$$ by **composition of simple operations** of $$\\frac{\\partial x_i}{\\partial t},\\ i=1,2,\\cdots,n$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13eaa414",
   "metadata": {},
   "source": [
    "### Automatic Differentiation - Forward Mode\n",
    "- **Notice:** Here is only my naive understanding about automatic differentiation since I haven't found some detailed mathematical explanation about it.\n",
    "- One naive way of find the partial derivative respect to $i$-th variable $\\frac{\\partial f}{\\partial x_i}$ in the function $$f=f(x_1,x_2,\\cdots,x_n)$$ the simplest way is to **construct** the chain rule ($\\frac{\\partial f}{\\partial t}$ is actually meaningless in this context) $$\\frac{\\partial f}{\\partial t}=\\underset{j=1}{\\overset{n}{\\Sigma}}\\frac{\\partial f}{\\partial x_j}\\frac{\\partial x_j}{\\partial t}$$ by setting $$\\frac{\\partial x_j}{\\partial t}=\\left\\{\\begin{aligned}&1&j=i\\\\&0&j\\ne i\\end{aligned}\\right.$$ we get $$\\frac{\\partial f}{\\partial t}=\\frac{\\partial f}{\\partial x_i}$$\n",
    "- That is to say, for each **decomposed simple operation**, the computer does not only calculate the **output**, but also simultaneously tracks the **derivatives of output respect to time** based on the input value and input derivative, thus **step by step** getting the final derivative respect to time, which is equal to the partial derivative\n",
    "- Since the computation is **straight forward**, this method to calculate partial derivative is called **forward mode**.\n",
    "- For example, for a function $$f(x_1,x_2)=\\text{ln}(x_1)+x_1x_2-\\text{sin}(x_2)$$ Decompose the function into simple operation nodes $$\\begin{aligned}v_{-1}&=x_1\\\\v_0&=x_2\\\\v_1&=\\text{ln}v_{-1}\\\\v_2&=v_{-1}\\times v_0\\\\v_3&=\\text{sin}v_0\\\\v_4&=v_1+v_2\\\\v_5&=v_4-v_3\\\\y&=v_5\\end{aligned}$$The forward mode computation graph is shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3401d723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.46.0 (20210118.1747)\r\n",
       " -->\r\n",
       "<!-- Title: ComputationGraph Pages: 1 -->\r\n",
       "<svg width=\"277pt\" height=\"151pt\"\r\n",
       " viewBox=\"0.00 0.00 277.19 151.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 147)\">\r\n",
       "<title>ComputationGraph</title>\r\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-147 273.19,-147 273.19,4 -4,4\"/>\r\n",
       "<!-- v_&#45;1 -->\r\n",
       "<g id=\"node1\" class=\"node\">\r\n",
       "<title>v_&#45;1</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"22.1\" cy=\"-112.5\" rx=\"22.2\" ry=\"22.2\"/>\r\n",
       "<text text-anchor=\"start\" x=\"13.1\" y=\"-109.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">v</text>\r\n",
       "<text text-anchor=\"start\" x=\"20.1\" y=\"-109.8\" font-family=\"Times New Roman,serif\" baseline-shift=\"sub\" font-size=\"14.00\">&#45;1</text>\r\n",
       "</g>\r\n",
       "<!-- v_1 -->\r\n",
       "<g id=\"node3\" class=\"node\">\r\n",
       "<title>v_1</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"99.69\" cy=\"-123.5\" rx=\"19.5\" ry=\"19.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"92.69\" y=\"-120.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">v</text>\r\n",
       "<text text-anchor=\"start\" x=\"99.69\" y=\"-120.8\" font-family=\"Times New Roman,serif\" baseline-shift=\"sub\" font-size=\"14.00\">1</text>\r\n",
       "</g>\r\n",
       "<!-- v_&#45;1&#45;&gt;v_1 -->\r\n",
       "<g id=\"edge1\" class=\"edge\">\r\n",
       "<title>v_&#45;1&#45;&gt;v_1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M44.16,-115.56C52.23,-116.74 61.58,-118.1 70.24,-119.36\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"69.92,-122.85 80.32,-120.82 70.93,-115.92 69.92,-122.85\"/>\r\n",
       "</g>\r\n",
       "<!-- v_2 -->\r\n",
       "<g id=\"node4\" class=\"node\">\r\n",
       "<title>v_2</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"99.69\" cy=\"-66.5\" rx=\"19.5\" ry=\"19.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"92.69\" y=\"-63.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">v</text>\r\n",
       "<text text-anchor=\"start\" x=\"99.69\" y=\"-63.8\" font-family=\"Times New Roman,serif\" baseline-shift=\"sub\" font-size=\"14.00\">2</text>\r\n",
       "</g>\r\n",
       "<!-- v_&#45;1&#45;&gt;v_2 -->\r\n",
       "<g id=\"edge2\" class=\"edge\">\r\n",
       "<title>v_&#45;1&#45;&gt;v_2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M41.4,-101.36C51.13,-95.44 63.24,-88.07 73.82,-81.64\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"75.89,-84.47 82.62,-76.28 72.25,-78.49 75.89,-84.47\"/>\r\n",
       "</g>\r\n",
       "<!-- v_0 -->\r\n",
       "<g id=\"node2\" class=\"node\">\r\n",
       "<title>v_0</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"22.1\" cy=\"-41.5\" rx=\"19.5\" ry=\"19.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"15.1\" y=\"-38.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">v</text>\r\n",
       "<text text-anchor=\"start\" x=\"22.1\" y=\"-38.8\" font-family=\"Times New Roman,serif\" baseline-shift=\"sub\" font-size=\"14.00\">0</text>\r\n",
       "</g>\r\n",
       "<!-- v_0&#45;&gt;v_2 -->\r\n",
       "<g id=\"edge3\" class=\"edge\">\r\n",
       "<title>v_0&#45;&gt;v_2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M41.01,-47.42C50.05,-50.41 61.21,-54.1 71.3,-57.44\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"70.31,-60.8 80.91,-60.62 72.51,-54.15 70.31,-60.8\"/>\r\n",
       "</g>\r\n",
       "<!-- v_3 -->\r\n",
       "<g id=\"node5\" class=\"node\">\r\n",
       "<title>v_3</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"174.69\" cy=\"-19.5\" rx=\"19.5\" ry=\"19.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"167.69\" y=\"-16.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">v</text>\r\n",
       "<text text-anchor=\"start\" x=\"174.69\" y=\"-16.8\" font-family=\"Times New Roman,serif\" baseline-shift=\"sub\" font-size=\"14.00\">3</text>\r\n",
       "</g>\r\n",
       "<!-- v_0&#45;&gt;v_3 -->\r\n",
       "<g id=\"edge4\" class=\"edge\">\r\n",
       "<title>v_0&#45;&gt;v_3</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M41.56,-38.8C67.42,-35.02 114.65,-28.12 145.07,-23.68\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"145.69,-27.13 155.07,-22.22 144.67,-20.2 145.69,-27.13\"/>\r\n",
       "</g>\r\n",
       "<!-- v_4 -->\r\n",
       "<g id=\"node6\" class=\"node\">\r\n",
       "<title>v_4</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"174.69\" cy=\"-76.5\" rx=\"19.5\" ry=\"19.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"167.69\" y=\"-73.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">v</text>\r\n",
       "<text text-anchor=\"start\" x=\"174.69\" y=\"-73.8\" font-family=\"Times New Roman,serif\" baseline-shift=\"sub\" font-size=\"14.00\">4</text>\r\n",
       "</g>\r\n",
       "<!-- v_1&#45;&gt;v_4 -->\r\n",
       "<g id=\"edge5\" class=\"edge\">\r\n",
       "<title>v_1&#45;&gt;v_4</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M116.53,-113.3C126.1,-107.14 138.49,-99.16 149.28,-92.21\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"151.37,-95.03 157.88,-86.68 147.58,-89.15 151.37,-95.03\"/>\r\n",
       "</g>\r\n",
       "<!-- v_2&#45;&gt;v_4 -->\r\n",
       "<g id=\"edge6\" class=\"edge\">\r\n",
       "<title>v_2&#45;&gt;v_4</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M119.11,-69.02C127.07,-70.11 136.55,-71.41 145.37,-72.62\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"144.89,-76.09 155.28,-73.98 145.84,-69.15 144.89,-76.09\"/>\r\n",
       "</g>\r\n",
       "<!-- v_5 -->\r\n",
       "<g id=\"node7\" class=\"node\">\r\n",
       "<title>v_5</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"249.69\" cy=\"-47.5\" rx=\"19.5\" ry=\"19.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"242.69\" y=\"-44.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">v</text>\r\n",
       "<text text-anchor=\"start\" x=\"249.69\" y=\"-44.8\" font-family=\"Times New Roman,serif\" baseline-shift=\"sub\" font-size=\"14.00\">5</text>\r\n",
       "</g>\r\n",
       "<!-- v_3&#45;&gt;v_5 -->\r\n",
       "<g id=\"edge8\" class=\"edge\">\r\n",
       "<title>v_3&#45;&gt;v_5</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M193.36,-26.28C201.88,-29.54 212.28,-33.53 221.76,-37.17\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"220.59,-40.47 231.18,-40.78 223.1,-33.93 220.59,-40.47\"/>\r\n",
       "</g>\r\n",
       "<!-- v_4&#45;&gt;v_5 -->\r\n",
       "<g id=\"edge7\" class=\"edge\">\r\n",
       "<title>v_4&#45;&gt;v_5</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M192.99,-69.63C201.56,-66.22 212.11,-62.03 221.72,-58.21\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"223.26,-61.37 231.26,-54.42 220.67,-54.86 223.26,-61.37\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x2890acdabb0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "f = Digraph('ComputationGraph')\n",
    "f.attr(rankdir='LR')\n",
    "f.attr('node', shape='circle')\n",
    "f.node('v_-1', label='<v<sub>-1</sub>>')\n",
    "f.node('v_0', label='<v<sub>0</sub>>')\n",
    "f.node('v_1', label='<v<sub>1</sub>>')\n",
    "f.node('v_2', label='<v<sub>2</sub>>')\n",
    "f.node('v_3', label='<v<sub>3</sub>>')\n",
    "f.node('v_4', label='<v<sub>4</sub>>')\n",
    "f.node('v_5', label='<v<sub>5</sub>>')\n",
    "f.edge('v_-1', 'v_1')\n",
    "f.edge('v_-1', 'v_2')\n",
    "f.edge('v_0', 'v_2')\n",
    "f.edge('v_0', 'v_3')\n",
    "f.edge('v_1', 'v_4')\n",
    "f.edge('v_2', 'v_4')\n",
    "f.edge('v_4', 'v_5')\n",
    "f.edge('v_3', 'v_5')\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18776008",
   "metadata": {},
   "source": [
    "- To find the **partial derivate** $\\frac{\\partial f}{\\partial x_1}$ when $x_1=2,x_2=5$, compute along the **forward evaluation trace**  first:$$\\begin{aligned}v_{-1}&=&x_1&=&2\\\\v_{0}&=&x_2&=&5\\\\v_1&=&\\text{ln}v_{-1}&=&\\text{ln}2\\\\v_2&=&v_{-1}\\times v_0&=&2\\times 5\\\\v_3&=&\\text{sin}v_0&=&\\text{sin}5\\\\v_4&=&v_1+v_2&=&0.693+10\\\\v_5&=&v_4-v_3&=&10.693+0.959\\\\y&=&v_5&=&11.652\\end{aligned}$$ Then set $\\dot{x_1}=1,\\ \\dot{x_2}=0$ and compute along the **forward derivative trace** (maybe also computed simultaneously along with the forward evaluation trace)$$\\begin{aligned}\\dot{v}_{-1}&=&\\dot{x}_1&=&1\\\\ \\dot{v}_{0}&=&\\dot{x}_2&=&0\\\\ \\dot{v}_1&=&\\dot{v}_{-1}/v_{-1}&=&1/2\\\\ \\dot{v}_2&=&\\dot{v}_{-1}\\times v_0+\\dot{v}_0\\times v_{-1}&=&1\\times 5 +0\\times 2\\\\ \\dot{v}_3&=&\\dot{v}_0\\times\\text{cos}v_0&=&0\\times\\text{cos}5\\\\ \\dot{v}_4&=&\\dot{v}_1+\\dot{v}_2&=&0.5+5\\\\ \\dot{v}_5&=&\\dot{v}_4-\\dot{v}_3&=&5.5-0\\\\ \\dot{y}&=&\\dot{v}_5&=&5.5\\end{aligned}$$ Therefore, the result is $$\\frac{\\partial f}{\\partial x_1}=\\frac{\\partial f}{\\partial t}=5.5$$ If $\\frac{\\partial f}{\\partial x_2}$ is also interested, the **forward derivative trace** needs to be computed again when setting $\\dot{x}_1=0,\\dot{x}_2=1$\n",
    "- **Comments**:\n",
    "    - For a function $f:\\mathbb{R}^n\\Rightarrow\\mathbb{R}^m$ with input $\\mathbf{x}\\in\\mathbb{R}^n$ and output $\\mathbf{y}\\in\\mathbb{R}^m$, needs to calculate $n$ times along the **forward derivative trace** for the partial derivatives $$\\frac{\\partial \\mathbf{y}}{\\partial x_j},\\ j=1,2,\\cdots,n$$ by sequentially setting $$\\frac{\\partial x_j}{\\partial t}=\\left\\{\\begin{aligned}&1&j=i\\\\&0&j\\ne i\\end{aligned}\\right.,\\ i=1,2,\\cdots,n$$ and only one time along the **forward evaluation trace** for the $m$-dimension output values $$y_1,y_2,\\cdots,y_m$$\n",
    "    - Get the partial derivatives of **all outputs** respect to **one variable** after computing along the derivative trace once\n",
    "    - **High efficiency** when $n<<m$\n",
    "    - **Low efficiency** when $n>>m$, which is common in machine learning and deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78065c46",
   "metadata": {},
   "source": [
    "### Automatic differentiation - Reverse Mode\n",
    "- Motivated by the **low efficiency** of *forward mode* when the derivatives of multiple variables are interested\n",
    "    - In machine learning and deep learning, usually the dimension of input parameters are huge (such as $10^6$) while the dimension of output is usually 1 (focusing on the loss function which produce a scalar)\n",
    "- To find the partial derivative respect to $i$-th variable $\\frac{\\partial f}{\\partial x_i}$ in the function $$f=f(x_1,x_2,\\cdots,x_n)$$ we can always decompose the function into simple operation nodes $$v_1,v_2,\\cdots,v_p$$ such that we can find some nodes $v_c,c\\in[1,M]$ to compose the derivative $$\\frac{\\partial y}{\\partial x_i}=\\frac{\\partial y}{\\partial v_{c_q}}\\frac{\\partial v_{c_{q}}}{\\partial v_{c_{q-1}}}\\cdots\\frac{\\partial v_{c_2}}{\\partial v_{c_1}}\\frac{\\partial v_{c_1}}{\\partial x_i}$$ Denote $$\\bar{v}_c=\\frac{\\partial y}{\\partial v_{c}}$$ The idea is to first compute following the **forward evaluation trace** same as that in *forward mode* while recording the **relationship** (such as the differential equation) between nodes, then sequentially calculate $$\\bar{v}_{c_q}=\\frac{\\partial y}{\\partial v_{c_q}},\\bar{v}_{c_{q-1}}=\\bar{v}_{c_q}\\frac{\\partial v_{c_q}}{\\partial v_{c_{q-1}}},\\cdots,\\frac{\\partial f}{\\partial x_i}=\\bar{v}_{c_1}\\frac{\\partial v_{c_1}}{\\partial x}$$\n",
    "- The example is still to find the partial derivatives at $x_1=2,x_2=5$ of the function $$f(x_1,x_2)=\\text{ln}(x_1)+x_1x_2-\\text{sin}(x_2)$$ Similarly, decompose the function into simple operation nodes $$\\begin{aligned}v_{-1}&=x_1\\\\v_0&=x_2\\\\v_1&=\\text{ln}v_{-1}\\\\v_2&=v_{-1}\\times v_0\\\\v_3&=\\text{sin}v_0\\\\v_4&=v_1+v_2\\\\v_5&=v_4-v_3\\\\y&=v_5\\end{aligned}$$ The **forward evaluation computation graph** would be the same of that in *forward mode*. Here show the **reverse adjoint computation graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9d96b022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.46.0 (20210118.1747)\r\n",
       " -->\r\n",
       "<!-- Title: ComputationGraph Pages: 1 -->\r\n",
       "<svg width=\"277pt\" height=\"151pt\"\r\n",
       " viewBox=\"0.00 0.00 277.19 151.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 147)\">\r\n",
       "<title>ComputationGraph</title>\r\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-147 273.19,-147 273.19,4 -4,4\"/>\r\n",
       "<!-- v_&#45;1 -->\r\n",
       "<g id=\"node1\" class=\"node\">\r\n",
       "<title>v_&#45;1</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"22.1\" cy=\"-41.5\" rx=\"22.2\" ry=\"22.2\"/>\r\n",
       "<text text-anchor=\"start\" x=\"13.1\" y=\"-38.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">v</text>\r\n",
       "<text text-anchor=\"start\" x=\"20.1\" y=\"-38.8\" font-family=\"Times New Roman,serif\" baseline-shift=\"sub\" font-size=\"14.00\">&#45;1</text>\r\n",
       "</g>\r\n",
       "<!-- v_0 -->\r\n",
       "<g id=\"node2\" class=\"node\">\r\n",
       "<title>v_0</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"22.1\" cy=\"-112.5\" rx=\"19.5\" ry=\"19.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"15.1\" y=\"-109.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">v</text>\r\n",
       "<text text-anchor=\"start\" x=\"22.1\" y=\"-109.8\" font-family=\"Times New Roman,serif\" baseline-shift=\"sub\" font-size=\"14.00\">0</text>\r\n",
       "</g>\r\n",
       "<!-- v_1 -->\r\n",
       "<g id=\"node3\" class=\"node\">\r\n",
       "<title>v_1</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"99.69\" cy=\"-19.5\" rx=\"19.5\" ry=\"19.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"92.69\" y=\"-16.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">v</text>\r\n",
       "<text text-anchor=\"start\" x=\"99.69\" y=\"-16.8\" font-family=\"Times New Roman,serif\" baseline-shift=\"sub\" font-size=\"14.00\">1</text>\r\n",
       "</g>\r\n",
       "<!-- v_1&#45;&gt;v_&#45;1 -->\r\n",
       "<g id=\"edge1\" class=\"edge\">\r\n",
       "<title>v_1&#45;&gt;v_&#45;1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M80.78,-24.71C72.57,-27.1 62.61,-30 53.3,-32.71\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"52.18,-29.39 43.56,-35.54 54.14,-36.11 52.18,-29.39\"/>\r\n",
       "</g>\r\n",
       "<!-- v_2 -->\r\n",
       "<g id=\"node4\" class=\"node\">\r\n",
       "<title>v_2</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"99.69\" cy=\"-76.5\" rx=\"19.5\" ry=\"19.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"92.69\" y=\"-73.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">v</text>\r\n",
       "<text text-anchor=\"start\" x=\"99.69\" y=\"-73.8\" font-family=\"Times New Roman,serif\" baseline-shift=\"sub\" font-size=\"14.00\">2</text>\r\n",
       "</g>\r\n",
       "<!-- v_2&#45;&gt;v_&#45;1 -->\r\n",
       "<g id=\"edge2\" class=\"edge\">\r\n",
       "<title>v_2&#45;&gt;v_&#45;1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M81.54,-68.56C72.76,-64.49 61.83,-59.43 51.81,-54.79\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"53.13,-51.54 42.58,-50.52 50.19,-57.9 53.13,-51.54\"/>\r\n",
       "</g>\r\n",
       "<!-- v_2&#45;&gt;v_0 -->\r\n",
       "<g id=\"edge3\" class=\"edge\">\r\n",
       "<title>v_2&#45;&gt;v_0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M81.54,-84.67C72,-89.21 59.93,-94.96 49.24,-100.05\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"47.45,-97.03 39.92,-104.49 50.46,-103.35 47.45,-97.03\"/>\r\n",
       "</g>\r\n",
       "<!-- v_3 -->\r\n",
       "<g id=\"node5\" class=\"node\">\r\n",
       "<title>v_3</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"174.69\" cy=\"-123.5\" rx=\"19.5\" ry=\"19.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"167.69\" y=\"-120.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">v</text>\r\n",
       "<text text-anchor=\"start\" x=\"174.69\" y=\"-120.8\" font-family=\"Times New Roman,serif\" baseline-shift=\"sub\" font-size=\"14.00\">3</text>\r\n",
       "</g>\r\n",
       "<!-- v_3&#45;&gt;v_0 -->\r\n",
       "<g id=\"edge4\" class=\"edge\">\r\n",
       "<title>v_3&#45;&gt;v_0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M155.23,-122.15C129.37,-120.26 82.14,-116.81 51.71,-114.59\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"51.94,-111.1 41.71,-113.86 51.43,-118.08 51.94,-111.1\"/>\r\n",
       "</g>\r\n",
       "<!-- v_4 -->\r\n",
       "<g id=\"node6\" class=\"node\">\r\n",
       "<title>v_4</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"174.69\" cy=\"-66.5\" rx=\"19.5\" ry=\"19.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"167.69\" y=\"-63.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">v</text>\r\n",
       "<text text-anchor=\"start\" x=\"174.69\" y=\"-63.8\" font-family=\"Times New Roman,serif\" baseline-shift=\"sub\" font-size=\"14.00\">4</text>\r\n",
       "</g>\r\n",
       "<!-- v_4&#45;&gt;v_1 -->\r\n",
       "<g id=\"edge5\" class=\"edge\">\r\n",
       "<title>v_4&#45;&gt;v_1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M157.85,-56.3C148.29,-50.14 135.9,-42.16 125.1,-35.21\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"126.81,-32.15 116.5,-29.68 123.02,-38.03 126.81,-32.15\"/>\r\n",
       "</g>\r\n",
       "<!-- v_4&#45;&gt;v_2 -->\r\n",
       "<g id=\"edge6\" class=\"edge\">\r\n",
       "<title>v_4&#45;&gt;v_2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M155.27,-69.02C147.32,-70.11 137.83,-71.41 129.02,-72.62\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"128.54,-69.15 119.11,-73.98 129.49,-76.09 128.54,-69.15\"/>\r\n",
       "</g>\r\n",
       "<!-- v_5 -->\r\n",
       "<g id=\"node7\" class=\"node\">\r\n",
       "<title>v_5</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"249.69\" cy=\"-94.5\" rx=\"19.5\" ry=\"19.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"242.69\" y=\"-91.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">v</text>\r\n",
       "<text text-anchor=\"start\" x=\"249.69\" y=\"-91.8\" font-family=\"Times New Roman,serif\" baseline-shift=\"sub\" font-size=\"14.00\">5</text>\r\n",
       "</g>\r\n",
       "<!-- v_5&#45;&gt;v_3 -->\r\n",
       "<g id=\"edge8\" class=\"edge\">\r\n",
       "<title>v_5&#45;&gt;v_3</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M231.39,-101.37C222.81,-104.78 212.26,-108.97 202.66,-112.78\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"201.12,-109.63 193.12,-116.57 203.7,-116.14 201.12,-109.63\"/>\r\n",
       "</g>\r\n",
       "<!-- v_5&#45;&gt;v_4 -->\r\n",
       "<g id=\"edge7\" class=\"edge\">\r\n",
       "<title>v_5&#45;&gt;v_4</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M231.02,-87.72C222.5,-84.45 212.1,-80.46 202.62,-76.83\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"203.79,-73.53 193.2,-73.21 201.28,-80.06 203.79,-73.53\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x2890acf6a30>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = Digraph('ComputationGraph')\n",
    "f.attr(rankdir='RL')\n",
    "f.attr('node', shape='circle')\n",
    "f.node('v_-1', label='<v<sub>-1</sub>>')\n",
    "f.node('v_0', label='<v<sub>0</sub>>')\n",
    "f.node('v_1', label='<v<sub>1</sub>>')\n",
    "f.node('v_2', label='<v<sub>2</sub>>')\n",
    "f.node('v_3', label='<v<sub>3</sub>>')\n",
    "f.node('v_4', label='<v<sub>4</sub>>')\n",
    "f.node('v_5', label='<v<sub>5</sub>>')\n",
    "f.edge('v_1', 'v_-1')\n",
    "f.edge('v_2', 'v_-1')\n",
    "f.edge('v_2', 'v_0')\n",
    "f.edge('v_3', 'v_0')\n",
    "f.edge('v_4', 'v_1')\n",
    "f.edge('v_4', 'v_2')\n",
    "f.edge('v_5', 'v_4')\n",
    "f.edge('v_5', 'v_3')\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a8beba",
   "metadata": {},
   "source": [
    "- First, compute along the **forward evaluation trace** $$\\begin{aligned}v_{-1}&=&x_1&=&2\\\\v_{0}&=&x_2&=&5\\\\v_1&=&\\text{ln}v_{-1}&=&\\text{ln}2\\\\v_2&=&v_{-1}\\times v_0&=&2\\times 5\\\\v_3&=&\\text{sin}v_0&=&\\text{sin}5\\\\v_4&=&v_1+v_2&=&0.693+10\\\\v_5&=&v_4-v_3&=&10.693+0.959\\\\y&=&v_5&=&11.652\\end{aligned}$$ Then compute along the **reverse adjoint trace** $$\\begin{aligned}\\bar{v}_5&=&\\frac{\\partial y}{\\partial v_5}&=&1&\\ &\\\\ \\bar{v}_4&=&\\bar{v}_5\\frac{\\partial v_5}{\\partial v_4}&=&\\bar{v}_5\\times 1&=&1\\\\ \\bar{v}_3&=&\\bar{v}_5\\frac{\\partial v_5}{\\partial v_3}&=&\\bar{v}_5\\times(-1)&=&-1\\\\ \\bar{v}_1&=&\\bar{v}_4\\frac{\\partial v_4}{\\partial v_1}&=&\\bar{v}_4\\times 1&=&1\\\\ \\bar{v}_2&=&\\bar{v}_4\\frac{\\partial v_4}{\\partial v_2}&=&\\bar{v}_4\\times 1&=&1\\\\ \\bar{v}_0&=&\\bar{v}_2\\frac{\\partial v_2}{\\partial v_0}+\\bar{v}_3\\frac{\\partial v_3}{\\partial v_0}&=&\\bar{v}_2\\times v_{-1}+\\bar{v}_3\\times\\text{cos}v_0&=&1.716\\\\ \\bar{v}_{-1}&=&\\bar{v}_1\\frac{\\partial v_1}{\\partial v_{-1}}+\\bar{v}_2\\frac{\\partial v_2}{\\partial v_{-1}}&=&\\bar{v}_1\\times\\frac{1}{v_{-1}}+\\bar{v}_2\\times v_0&=&5.5\\end{aligned}$$ Therefore, the result is $$\\begin{aligned}\\frac{\\partial f}{\\partial x_1}&=&\\bar{v}_{-1}&=&5.5\\\\\\frac{\\partial f}{\\partial x_2}&=&\\bar{v}_0&=&1.716\\end{aligned}$$\n",
    "- **Comments**: \n",
    "    - For a function $f:\\mathbb{R}^n\\Rightarrow\\mathbb{R}^m$ with input $\\mathbf{x}\\in\\mathbb{R}^n$ and output $\\mathbf{y}\\in\\mathbb{R}^m$, needs to calculate $m$ times along the **reverse adjoint trace**\n",
    "    - Get the partial derivatives of **one output** respect to **all variables** after computing along the reverse adjoint trace once\n",
    "        - Fits the idea of calculating **gradients**\n",
    "    - **High efficiency** when $n>>m$\n",
    "    - **Low efficiency** when $n<<m$\n",
    "    - Frequently used in ML/DL tasks and is supported by PyTorch, Tensorflow, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e97ef8",
   "metadata": {},
   "source": [
    "### Computation graph and AutoGrad in PyTorch\n",
    "- As mentioned above, PyTorch supports **reverse mode automatic differentiation**\n",
    "    - PyTorch automatically creates a computation graph if **requires_grad=True**\n",
    "    - For a given variable with **requires_grad=True**, identify the operations and record the required information for reverse adjoint trace computation\n",
    "    - Can be checked by viewing the **requires_grad** attributes of independent variables\n",
    "    - Use the **make\\_dots** method from **torchviz** module to visualize the computation graph\n",
    "        - Need support from **graphviz**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "91e20cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.) False\n",
      "tensor(80.) False\n"
     ]
    }
   ],
   "source": [
    "# The default setting is requires_grad = False\n",
    "x = torch.tensor(5.)\n",
    "y = 3*x**2+x\n",
    "print(x,x.requires_grad)\n",
    "print(y,y.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "94594def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5., requires_grad=True) True\n",
      "tensor(76.1643, grad_fn=<AddBackward0>) True\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.46.0 (20210118.1747)\r\n",
       " -->\r\n",
       "<!-- Pages: 1 -->\r\n",
       "<svg width=\"221pt\" height=\"357pt\"\r\n",
       " viewBox=\"0.00 0.00 220.89 357.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 353)\">\r\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-353 216.89,-353 216.89,4 -4,4\"/>\r\n",
       "<!-- 2787609483904 -->\r\n",
       "<g id=\"node1\" class=\"node\">\r\n",
       "<title>2787609483904</title>\r\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"141.39,-19 87.39,-19 87.39,0 141.39,0 141.39,-19\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"114.39\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\r\n",
       "</g>\r\n",
       "<!-- 2787615141696 -->\r\n",
       "<g id=\"node2\" class=\"node\">\r\n",
       "<title>2787615141696</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"158.89,-74 69.89,-74 69.89,-55 158.89,-55 158.89,-74\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"114.39\" y=\"-62\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\r\n",
       "</g>\r\n",
       "<!-- 2787615141696&#45;&gt;2787609483904 -->\r\n",
       "<g id=\"edge10\" class=\"edge\">\r\n",
       "<title>2787615141696&#45;&gt;2787609483904</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M114.39,-54.75C114.39,-47.8 114.39,-37.85 114.39,-29.13\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"117.89,-29.09 114.39,-19.09 110.89,-29.09 117.89,-29.09\"/>\r\n",
       "</g>\r\n",
       "<!-- 2787615139872 -->\r\n",
       "<g id=\"node3\" class=\"node\">\r\n",
       "<title>2787615139872</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"105.89,-129 16.89,-129 16.89,-110 105.89,-110 105.89,-129\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"61.39\" y=\"-117\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\r\n",
       "</g>\r\n",
       "<!-- 2787615139872&#45;&gt;2787615141696 -->\r\n",
       "<g id=\"edge1\" class=\"edge\">\r\n",
       "<title>2787615139872&#45;&gt;2787615141696</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M70.14,-109.75C77.86,-102.03 89.3,-90.6 98.61,-81.28\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"101.21,-83.64 105.8,-74.09 96.26,-78.69 101.21,-83.64\"/>\r\n",
       "</g>\r\n",
       "<!-- 2787615113424 -->\r\n",
       "<g id=\"node4\" class=\"node\">\r\n",
       "<title>2787615113424</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"108.89,-184 19.89,-184 19.89,-165 108.89,-165 108.89,-184\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"64.39\" y=\"-172\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\r\n",
       "</g>\r\n",
       "<!-- 2787615113424&#45;&gt;2787615139872 -->\r\n",
       "<g id=\"edge2\" class=\"edge\">\r\n",
       "<title>2787615113424&#45;&gt;2787615139872</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M63.9,-164.75C63.5,-157.8 62.94,-147.85 62.45,-139.13\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"65.94,-138.88 61.88,-129.09 58.95,-139.27 65.94,-138.88\"/>\r\n",
       "</g>\r\n",
       "<!-- 2787615113568 -->\r\n",
       "<g id=\"node5\" class=\"node\">\r\n",
       "<title>2787615113568</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"108.89,-239 19.89,-239 19.89,-220 108.89,-220 108.89,-239\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"64.39\" y=\"-227\" font-family=\"monospace\" font-size=\"10.00\">PowBackward0</text>\r\n",
       "</g>\r\n",
       "<!-- 2787615113568&#45;&gt;2787615113424 -->\r\n",
       "<g id=\"edge3\" class=\"edge\">\r\n",
       "<title>2787615113568&#45;&gt;2787615113424</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M64.39,-219.75C64.39,-212.8 64.39,-202.85 64.39,-194.13\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"67.89,-194.09 64.39,-184.09 60.89,-194.09 67.89,-194.09\"/>\r\n",
       "</g>\r\n",
       "<!-- 2787615113376 -->\r\n",
       "<g id=\"node6\" class=\"node\">\r\n",
       "<title>2787615113376</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"114.89,-294 13.89,-294 13.89,-275 114.89,-275 114.89,-294\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"64.39\" y=\"-282\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\r\n",
       "</g>\r\n",
       "<!-- 2787615113376&#45;&gt;2787615139872 -->\r\n",
       "<g id=\"edge6\" class=\"edge\">\r\n",
       "<title>2787615113376&#45;&gt;2787615139872</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M47.5,-274.95C34.69,-267.43 18.01,-255.15 10.39,-239 -3.64,-209.25 -3.22,-194.94 10.39,-165 16.02,-152.63 26.96,-142.36 37.28,-134.81\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"39.35,-137.63 45.66,-129.12 35.42,-131.84 39.35,-137.63\"/>\r\n",
       "</g>\r\n",
       "<!-- 2787615113376&#45;&gt;2787615113568 -->\r\n",
       "<g id=\"edge4\" class=\"edge\">\r\n",
       "<title>2787615113376&#45;&gt;2787615113568</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M64.39,-274.75C64.39,-267.8 64.39,-257.85 64.39,-249.13\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"67.89,-249.09 64.39,-239.09 60.89,-249.09 67.89,-249.09\"/>\r\n",
       "</g>\r\n",
       "<!-- 2787615113664 -->\r\n",
       "<g id=\"node9\" class=\"node\">\r\n",
       "<title>2787615113664</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"209.89,-239 126.89,-239 126.89,-220 209.89,-220 209.89,-239\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"168.39\" y=\"-227\" font-family=\"monospace\" font-size=\"10.00\">SinBackward</text>\r\n",
       "</g>\r\n",
       "<!-- 2787615113376&#45;&gt;2787615113664 -->\r\n",
       "<g id=\"edge9\" class=\"edge\">\r\n",
       "<title>2787615113376&#45;&gt;2787615113664</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M81.1,-274.98C97.61,-266.57 123.09,-253.59 142.27,-243.81\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"144.06,-246.83 151.38,-239.17 140.88,-240.59 144.06,-246.83\"/>\r\n",
       "</g>\r\n",
       "<!-- 2787615067520 -->\r\n",
       "<g id=\"node7\" class=\"node\">\r\n",
       "<title>2787615067520</title>\r\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"91.39,-349 37.39,-349 37.39,-330 91.39,-330 91.39,-349\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"64.39\" y=\"-337\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\r\n",
       "</g>\r\n",
       "<!-- 2787615067520&#45;&gt;2787615113376 -->\r\n",
       "<g id=\"edge5\" class=\"edge\">\r\n",
       "<title>2787615067520&#45;&gt;2787615113376</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M64.39,-329.75C64.39,-322.8 64.39,-312.85 64.39,-304.13\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"67.89,-304.09 64.39,-294.09 60.89,-304.09 67.89,-304.09\"/>\r\n",
       "</g>\r\n",
       "<!-- 2787615141408 -->\r\n",
       "<g id=\"node8\" class=\"node\">\r\n",
       "<title>2787615141408</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"212.89,-129 123.89,-129 123.89,-110 212.89,-110 212.89,-129\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"168.39\" y=\"-117\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\r\n",
       "</g>\r\n",
       "<!-- 2787615141408&#45;&gt;2787615141696 -->\r\n",
       "<g id=\"edge7\" class=\"edge\">\r\n",
       "<title>2787615141408&#45;&gt;2787615141696</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M159.48,-109.75C151.61,-102.03 139.96,-90.6 130.47,-81.28\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"132.73,-78.6 123.14,-74.09 127.83,-83.59 132.73,-78.6\"/>\r\n",
       "</g>\r\n",
       "<!-- 2787615113664&#45;&gt;2787615141408 -->\r\n",
       "<g id=\"edge8\" class=\"edge\">\r\n",
       "<title>2787615113664&#45;&gt;2787615141408</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M168.39,-219.66C168.39,-202.17 168.39,-162.8 168.39,-139.27\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"171.89,-139.16 168.39,-129.16 164.89,-139.16 171.89,-139.16\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x2890acf68e0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the torchviz module for visualization\n",
    "from torchviz import make_dot\n",
    "x = torch.tensor(5., requires_grad=True)\n",
    "y = 3*x**2+x+4*torch.sin(x)\n",
    "# Independent variable would show the requires_grad attribute\n",
    "print(x,x.requires_grad)\n",
    "# Dependent variable would show the grad_fn attribute\n",
    "print(y,y.requires_grad)\n",
    "make_dot(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f09bc4e",
   "metadata": {},
   "source": [
    "- Notice the **grad_fn** attribute. Tensor use this attribute to do the backwards computation.\n",
    "- When the dimension of input tensor is greater than one, the dimension of each step would also show on the graph\n",
    "    - Very useful when building neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "628c4c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.46.0 (20210118.1747)\r\n",
       " -->\r\n",
       "<!-- Pages: 1 -->\r\n",
       "<svg width=\"198pt\" height=\"247pt\"\r\n",
       " viewBox=\"0.00 0.00 198.00 247.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 243)\">\r\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-243 194,-243 194,4 -4,4\"/>\r\n",
       "<!-- 2787614971456 -->\r\n",
       "<g id=\"node1\" class=\"node\">\r\n",
       "<title>2787614971456</title>\r\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"135,-19 58,-19 58,0 135,0 135,-19\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"96.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> (3, 4, 4)</text>\r\n",
       "</g>\r\n",
       "<!-- 2787615114576 -->\r\n",
       "<g id=\"node2\" class=\"node\">\r\n",
       "<title>2787615114576</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"141,-74 52,-74 52,-55 141,-55 141,-74\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"96.5\" y=\"-62\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\r\n",
       "</g>\r\n",
       "<!-- 2787615114576&#45;&gt;2787614971456 -->\r\n",
       "<g id=\"edge6\" class=\"edge\">\r\n",
       "<title>2787615114576&#45;&gt;2787614971456</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M96.5,-54.75C96.5,-47.8 96.5,-37.85 96.5,-29.13\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"100,-29.09 96.5,-19.09 93,-29.09 100,-29.09\"/>\r\n",
       "</g>\r\n",
       "<!-- 2787615114000 -->\r\n",
       "<g id=\"node3\" class=\"node\">\r\n",
       "<title>2787615114000</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"89,-129 0,-129 0,-110 89,-110 89,-129\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"44.5\" y=\"-117\" font-family=\"monospace\" font-size=\"10.00\">PowBackward0</text>\r\n",
       "</g>\r\n",
       "<!-- 2787615114000&#45;&gt;2787615114576 -->\r\n",
       "<g id=\"edge1\" class=\"edge\">\r\n",
       "<title>2787615114000&#45;&gt;2787615114576</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M53.09,-109.75C60.66,-102.03 71.88,-90.6 81.01,-81.28\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"83.57,-83.68 88.07,-74.09 78.57,-78.78 83.57,-83.68\"/>\r\n",
       "</g>\r\n",
       "<!-- 2787615114288 -->\r\n",
       "<g id=\"node4\" class=\"node\">\r\n",
       "<title>2787615114288</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"147,-184 46,-184 46,-165 147,-165 147,-184\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"96.5\" y=\"-172\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\r\n",
       "</g>\r\n",
       "<!-- 2787615114288&#45;&gt;2787615114000 -->\r\n",
       "<g id=\"edge2\" class=\"edge\">\r\n",
       "<title>2787615114288&#45;&gt;2787615114000</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M87.91,-164.75C80.34,-157.03 69.12,-145.6 59.99,-136.28\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"62.43,-133.78 52.93,-129.09 57.43,-138.68 62.43,-133.78\"/>\r\n",
       "</g>\r\n",
       "<!-- 2787615114480 -->\r\n",
       "<g id=\"node6\" class=\"node\">\r\n",
       "<title>2787615114480</title>\r\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"190,-129 107,-129 107,-110 190,-110 190,-129\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"148.5\" y=\"-117\" font-family=\"monospace\" font-size=\"10.00\">SinBackward</text>\r\n",
       "</g>\r\n",
       "<!-- 2787615114288&#45;&gt;2787615114480 -->\r\n",
       "<g id=\"edge5\" class=\"edge\">\r\n",
       "<title>2787615114288&#45;&gt;2787615114480</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M105.09,-164.75C112.66,-157.03 123.88,-145.6 133.01,-136.28\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"135.57,-138.68 140.07,-129.09 130.57,-133.78 135.57,-138.68\"/>\r\n",
       "</g>\r\n",
       "<!-- 2787533462464 -->\r\n",
       "<g id=\"node5\" class=\"node\">\r\n",
       "<title>2787533462464</title>\r\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"135,-239 58,-239 58,-220 135,-220 135,-239\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"96.5\" y=\"-227\" font-family=\"monospace\" font-size=\"10.00\"> (3, 4, 4)</text>\r\n",
       "</g>\r\n",
       "<!-- 2787533462464&#45;&gt;2787615114288 -->\r\n",
       "<g id=\"edge3\" class=\"edge\">\r\n",
       "<title>2787533462464&#45;&gt;2787615114288</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M96.5,-219.75C96.5,-212.8 96.5,-202.85 96.5,-194.13\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"100,-194.09 96.5,-184.09 93,-194.09 100,-194.09\"/>\r\n",
       "</g>\r\n",
       "<!-- 2787615114480&#45;&gt;2787615114576 -->\r\n",
       "<g id=\"edge4\" class=\"edge\">\r\n",
       "<title>2787615114480&#45;&gt;2787615114576</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M139.91,-109.75C132.34,-102.03 121.12,-90.6 111.99,-81.28\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"114.43,-78.78 104.93,-74.09 109.43,-83.68 114.43,-78.78\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x2890acf0520>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn((3,4,4),requires_grad=True)\n",
    "y = x**2 + torch.sin(x)\n",
    "make_dot(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b02fda",
   "metadata": {},
   "source": [
    "- One can access the gradient by calling **backward()** method\n",
    "- After invoke **backward()** method on the dependent variable we are interested in, the partial derivative would automatically be returned to the **grad** attribute of variables contributed to that dependent variable\n",
    "- For **independent** variables, we can directly call **backward()** method and see the gradients\n",
    "- In the following case: $$z=x_1^2+x_2^2$$ The partial derivatives at $x_1=5,x_2=2$ are $$\\frac{\\partial z}{\\partial x_1}=2x_1=10,\\frac{\\partial z}{\\partial x_2}=2x_2=4$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a617c1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5., requires_grad=True) tensor(10.)\n",
      "tensor(2., requires_grad=True) tensor(4.)\n",
      "tensor(29., grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x_1 = torch.tensor(5.,requires_grad=True)\n",
    "x_2 = torch.tensor(2.,requires_grad=True)\n",
    "z = x_1**2 + x_2**2\n",
    "z.backward()\n",
    "print(x_1,x_1.grad)\n",
    "print(x_2,x_2.grad)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36dbd03",
   "metadata": {},
   "source": [
    "- For **intermediate dependent** variables (*non-leaf tensor* in pytorch documentation) used in computation, the gradient value is usually not considered and would be cleared after the computation along reverse adjoint trace.\n",
    "- If the value is indeed needed, the **retain_grad()** method should be invoked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e9262122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5., requires_grad=True) tensor(10.)\n",
      "tensor(2., requires_grad=True) tensor(2.)\n",
      "tensor(2., grad_fn=<MulBackward0>) tensor(1.)\n",
      "tensor(27., grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x_1 = torch.tensor(5.,requires_grad=True)\n",
    "x_2 = torch.tensor(2.,requires_grad=True)\n",
    "y = 0.5*x_2**2\n",
    "y.retain_grad()\n",
    "z = x_1**2 + y\n",
    "z.backward()\n",
    "print(x_1,x_1.grad)\n",
    "print(x_2,x_2.grad)\n",
    "print(y,y.grad)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71aef6f3",
   "metadata": {},
   "source": [
    "- It needs to be noticed that the gradients accumulate when calling **backward()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "891810ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5., requires_grad=True) tensor(30.)\n",
      "tensor(75., grad_fn=<MulBackward0>)\n",
      "tensor(5., requires_grad=True) tensor(60.)\n",
      "tensor(75., grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(5.,requires_grad=True)\n",
    "for ii in range(2):\n",
    "    y = 3*x**2\n",
    "    y.backward()\n",
    "    print(x,x.grad)\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8740f5a",
   "metadata": {},
   "source": [
    "- Therefore, when calculating the gradients repeated in loops, we usually need to **zero** the gradients before calling **backward()** method, by calling **zero_()** method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ee300d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'zero_'\n",
      "tensor(5., requires_grad=True) tensor(30.)\n",
      "tensor(75., grad_fn=<MulBackward0>)\n",
      "tensor(5., requires_grad=True) tensor(30.)\n",
      "tensor(75., grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(5.,requires_grad=True)\n",
    "for ii in range(2):\n",
    "    try:\n",
    "        x.grad.zero_()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    y = 3*x**2\n",
    "    y.backward()\n",
    "    print(x,x.grad)\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40829ad7",
   "metadata": {},
   "source": [
    "- Sometimes, we would need to call the **backward()** method multiple times, like using MSE loss and Cross-Entropy loss separately for localization and detection in CV. In this case, **retain_graph** should be set to **True** except in the last **backward()** method if any **intermediate dependent variables** are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "90a8f7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5., requires_grad=True) tensor(116.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(5.,requires_grad=True)\n",
    "y = x**2\n",
    "z_1 = x + y\n",
    "z_2 = x**2 + y\n",
    "z_3 = x**3 + y\n",
    "z_1.backward(retain_graph=True)\n",
    "z_2.backward(retain_graph=True)\n",
    "z_3.backward()\n",
    "print(x,x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4077f765",
   "metadata": {},
   "source": [
    "- Generally speaking, PyTorch can compute gradients for any number of parameters and any complex functions, as long as the decomposed operation is differentiable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "541c95b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2., 3., 4.], requires_grad=True)\n",
      "tensor(30., grad_fn=<SumBackward0>)\n",
      "tensor([0., 2., 4., 6., 8.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(5.).requires_grad_(True)\n",
    "y = torch.sum(x**2)\n",
    "y.backward()\n",
    "print(x)\n",
    "print(y)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fade2998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2., 3., 4.], requires_grad=True)\n",
      "tensor(11.4877, grad_fn=<MeanBackward0>)\n",
      "tensor([1.0000, 1.2000, 1.1600, 1.1200, 1.0941])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(5.).requires_grad_(True)\n",
    "y = torch.mean(torch.log(x**2+1)+5*x)\n",
    "y.backward()\n",
    "print(x)\n",
    "print(y)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5cf6e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
