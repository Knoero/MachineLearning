{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3c44d4d",
   "metadata": {},
   "source": [
    "**Information:** *A brief review of Linear Algebra needed in Machine Learning.*\n",
    "\n",
    "**Written by:** *Zihao Xu*\n",
    "\n",
    "**Last update date:**: *05.20.2020*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6a0d4c",
   "metadata": {},
   "source": [
    "# Basic Concepts\n",
    "\n",
    "## Scalars, Vectors, Matrices and Tensors\n",
    "\n",
    "### Scalars\n",
    "- Single number\n",
    "- Denoted as italic lowercase letter such as $a$, $b$, $c$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d2731e",
   "metadata": {},
   "source": [
    "### Vectors\n",
    "- Array of numbers\n",
    "- Usually consider vectors to be \"column vectors\"\n",
    "- Denoted as lowercase letter (often bolded)\n",
    "    > $\\textbf{x}=\\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\x_d \\end{bmatrix}$\n",
    "- Dimension is often denoted by $d$, $D$, or $p$\n",
    "    > $\\textbf{x} \\in \\mathbb{R}^d$\n",
    "- Access elements via subscript\n",
    "    > $x_i$ is the $i$-th element"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c885d1eb",
   "metadata": {},
   "source": [
    "### Matrices\n",
    "- 2D array of numbers\n",
    "- Denoted as uppercase letter (often bolded)\n",
    "    > $\\mathbf{A}=\\begin{bmatrix}A_{1,1} & \\cdots & A_{1,n}\\\\\\vdots & \\ddots & \\vdots \\\\A_{m,1} & \\cdots & A_{m,n}\\end{bmatrix}$\n",
    "- Dimension is often denoted by $m\\times n$\n",
    "    > $\\textbf{A} \\in \\mathbb{R}^{m \\times n}$\n",
    "- Access elements by double subscript \n",
    "    > $X_{i,j}$ or $x_{i,j}$ is the $i,j$-th entry of the matrix\n",
    "- Access rows or columns via subscript or numpy notation\n",
    "    > $X_{i,:}$ is the $i$-th row, $X_{:,j}$ is the $j$-th column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422121fa",
   "metadata": {},
   "source": [
    "### Tensors\n",
    "- n-D array, array with more than two axes\n",
    "    > $\\textbf{A}\\in \\mathbb{R}^{c\\times w\\times h}$\n",
    "- Other notations are similar with Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5022fa0c",
   "metadata": {},
   "source": [
    "### Addition of matrices, scalar multiplication and addition\n",
    "- When $\\textbf{A}=[A_{i,j}]$ and $\\textbf{B}=[B_{i,j}]$ have the same shape, the sum of them is written as $\\textbf{C}=\\textbf{A}+\\textbf{B}$ where $C_{i,j}=A_{i,j}+B_{i,j}$.\n",
    "    - In general, matrices of different sizes cannot be added.\n",
    "    - However, in the context of Deep Learning, notations like $\\textbf{C}=\\textbf{A}+\\textbf{b}$ is allowed where $C_{i,j}=A_{i,j}+b_{j}$, which means the vector $\\mathbf{b}$ is added to each row of the matrix. This is to avoid the need to define a matrix with $\\mathbf{b}$ copied into each row before doing the addition, This implicit copying is called **broadcasting**.\n",
    "- The product of any $m\\times n$ matrix $\\mathbf{A}=[A_{i,j}]$ and any scalar $c$ is written as $\\mathbf{C}=c\\mathbf{A}$ where $C_{i,j}=c\\cdot A_{i,j}$.\n",
    "- Similarly, the addition of any $m\\times n$ matrix $\\mathbf{A}=[A_{i,j}]$ and any scalar $b$ is written as $\\mathbf{C}=\\mathbf{A}+b$ where $C_{i,j}=A_{i,j}+b$.\n",
    "- Common calculation rules\n",
    "    - $\\mathbf{A}+\\mathbf{B}=\\mathbf{B}+\\mathbf{A}$\n",
    "    - $(\\mathbf{A}+\\mathbf{B})+\\mathbf{C}=\\mathbf{A}+(\\mathbf{B}+\\mathbf{C})$\n",
    "    - $c(\\mathbf{A}+\\mathbf{B})=c\\mathbf{A}+c\\mathbf{B}$\n",
    "    - $(c+k)\\mathbf{A}=c\\mathbf{A}+k\\mathbf{A}$\n",
    "    - $c(k\\mathbf{A})=ck\\mathbf{A}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c3a557",
   "metadata": {},
   "source": [
    "### Multiplication (Standard Product)\n",
    "- The product $\\mathbf{C}=\\mathbf{A}\\mathbf{B}$ of an $m\\times n_1$ matrix $\\mathbf{A}=[A_{i,j}]$ times an $n_2\\times p$ matrix $\\mathbf{B}=[B_{i,j}]$ is defined if and only if $n_1=n_2$ and then $\\mathbf{C}$ will be an $m\\times p$ matrix $\\mathbf{C}$ with entries\n",
    "$$C_{i,j}=\\overset{n}{\\underset{k}{\\Sigma}}A_{i,k}B{k,j}$$\n",
    "- Called standard product or matrix product.\n",
    "- Common calculation rules\n",
    "    - $(k\\mathbf{A})\\mathbf{B}=k(\\mathbf{A}\\mathbf{B})=\\mathbf{A}(k\\mathbf{B})$\n",
    "    - $\\mathbf{A}(\\mathbf{B}\\mathbf{C})=(\\mathbf{A}\\mathbf{B})\\mathbf{C}$\n",
    "    - $(\\mathbf{A}+\\mathbf{B})\\mathbf{C}=\\mathbf{A}\\mathbf{C}+\\mathbf{B}\\mathbf{C}$\n",
    "    - $\\mathbf{C}(\\mathbf{A}+\\mathbf{B})=\\mathbf{C}\\mathbf{A}+\\mathbf{C}\\mathbf{B}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd499984",
   "metadata": {},
   "source": [
    "### Element-wise product\n",
    "- A matrix containing the product of the individual elements from two matrix have the same size.\n",
    "- Denoted by $\\mathbf{C}=\\mathbf{A}\\odot\\mathbf{B}$ where $C_{i,j}=A_{i,j}\\cdot B_{i,j}$\n",
    "- Also called Hadamard product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1fd19b",
   "metadata": {},
   "source": [
    "### Transposition of Matrices and Vectors\n",
    "- Denoted as $\\mathbf{A}^T$\n",
    "- The transpose of an $m\\times n$ matrix $\\mathbf{A}=[A_{i,j}]$ is the $n\\times m$ matrix $\\mathbf{A}^T$ that has the first row of $\\mathbf{A}$ as its first column, the second row as its second column, and so on.\n",
    "    > $\\mathbf{A}^T=[A_{j,i}]=\\begin{bmatrix}A_{1,1} & \\cdots & A_{m,1}\\\\\\vdots & \\ddots & \\vdots \\\\A_{1,n} & \\cdots & A_{m,n}\\end{bmatrix}$\n",
    "- For vector $\\mathbf{v}$, the transpose changes it from a column vector to a row vector.\n",
    "    > $\\mathbf{x}=\\begin{bmatrix}x_1 \\\\x_2 \\\\\\vdots \\\\x_d\\end{bmatrix}$, \n",
    "    $\\mathbf{x}^T=\\begin{bmatrix}x_1 & x_2 & \\cdots & x_d\\end{bmatrix}$\n",
    "- Rules for transposition\n",
    "    - $(\\mathbf{A}^T)^T=\\mathbf{A}$\n",
    "    - $(\\mathbf{A}+\\mathbf{B})^T=\\mathbf{A}^T+\\mathbf{B}^T$\n",
    "    - $(c\\mathbf{A})^T=c\\mathbf{A}^T$\n",
    "    - $(\\mathbf{A}\\mathbf{B})^T=\\mathbf{B}^T\\mathbf{A}^T$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cd3d3f",
   "metadata": {},
   "source": [
    "### Special Matrices\n",
    "- Symmetric matrix: $\\mathbf{A}^T=\\mathbf{A},A_{i,j}=A_{j,i}$\n",
    "- Skew-symmetric matrix: $\\mathbf{A}^T=-\\mathbf{A}$\n",
    "- Triangular matrix:\n",
    "    - Upper triangular matrix can have non-zero entries only **on and above** the diagonal\n",
    "    - Lower triangular matrix can have non-zero entries only **on and below** the diagonal\n",
    "- Identity matrix:\n",
    "    - Identity matrix of size $n$ is the $n\\times n$ square matrix with ones on the main diagonal and zeros elsewhere. It is denoted by $\\mathbf{I}_n$ or simply by $\\mathbf{I}$ if the size is immaterial or can be trivially determined by the context.\n",
    "    - Some times called unit matrix (depends on the context).\n",
    "- Scalar matrix:\n",
    "    - Any multiple of an Identity matrix.\n",
    "- Diagonal matrix:\n",
    "    - A square matrix in which the entries outside the diagonal are all zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63d5129",
   "metadata": {},
   "source": [
    "## Linear System of equations\n",
    "### Represent linear set of equations in matrix equations\n",
    "- Linear set of equations can be compactly represented as matrix equation\n",
    "- In general:\n",
    "    $$\\begin{aligned}\n",
    "    a_{1,1}x_1+a_{1,2}x_2+ &\\cdots+ a_{1,n}x_n=b_1\\\\\n",
    "    a_{2,1}x_1+a_{2,2}x_2+ &\\cdots+ a_{2,n}x_n=b_2\\\\\n",
    "    &\\vdots\\\\\n",
    "    a_{m,1}x_1+a_{m,2}x_2+ &\\cdots+ a_{m,n}x_n=b_m\n",
    "    \\end{aligned}\n",
    "    $$\n",
    "    is **equivalent** to:\n",
    "    $$\\mathbf{Ax}=\\mathbf{b}$$\n",
    "    where $\\mathbf{A}\\in \\mathbb{R}^{m\\times n}$,$\\mathbf{x}\\in \\mathbb{R}^n$,$\\mathbf{b}\\in \\mathbb{R}^m$\n",
    "- Augmented matrix\n",
    "    $$\\tilde{\\mathbf{A}}=[\\mathbf{A},\\mathbf{b}]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acfd5e2",
   "metadata": {},
   "source": [
    "### Gaussian Elimination\n",
    "- **Goal**: Bring system to a triangular form\n",
    "- **Step**: \n",
    "    - Elementary operations on equations $\\longleftrightarrow$ Operation on matrices\n",
    "    - Interchange of two equations $\\longleftrightarrow$ Interchange two rows in a matrix\n",
    "    - Addition of a constant $\\longleftrightarrow$ Addition of a constant\n",
    "- Row equivalent\n",
    "    - We call a linear system $S_1$ row-equivalent to a linear system $S_2$ if $S_1$ can be obtained by finitely many row operations from $S_2$.\n",
    "- Theorem\n",
    "    - Row-equivalent linear systems have the same set of solutions.\n",
    "- Solution by Gaussian Elimination\n",
    "    - System:\n",
    "        - $\\mathbf{Ax}=\\mathbf{b}$ with augmented matrix $\\tilde{\\mathbf{A}}=[\\mathbf{A},\\mathbf{b}]$\n",
    "        - $\\mathbf{A}\\in \\mathbb{R}^{m\\times n}$,$\\mathbf{x}\\in \\mathbb{R}^n$,$\\mathbf{b}\\in \\mathbb{R}^m$\n",
    "    - Step 1: \n",
    "        - Pivot row: First row of $\\tilde{\\mathbf{A}}$\n",
    "        - Pivot: Coefficient of the $x_1$ term in pivot row\n",
    "        - Use pivot row to eliminate $x_1$ term in all other rows below\n",
    "    - Step 2:\n",
    "        - First equation remains as it is\n",
    "        - Pivot row: Second row of $\\tilde{\\mathbf{A}}$\n",
    "        - Pivot: Coefficient of the $x_2$ term in pivot row\n",
    "        - Use pivot row to eliminate $x_2$ term in all other rows below\n",
    "    - Step 3:\n",
    "        - Repeat the procedure which moves the pivot row from $s$ to $s+1$ and set pivot to be the coefficient of $x_{s+1}$ term in pivot row in each step, until $\\mathbf{A}$ is in upper triangular form\n",
    "    - Step 4: \n",
    "        - Back-substitution to get $x_n$, $x_{n-1}$, ..., $x_2$, $x_1$ sequentially"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f7f1a5",
   "metadata": {},
   "source": [
    "### Classification of solutions of Linear Systems\n",
    "- At the end of Gaussian elimination, $\\mathbf{A}$ is in upper triangular form (row echelon form)\n",
    "    - $r$ = number of non-zero rows in $\\tilde{\\mathbf{A}}$ = **rank** of $\\tilde{\\mathbf{A}}$, $r \\le m$\n",
    "- In general, three possible cases\n",
    "    - Consistent if $r=m$ or $r<m$ but $\\tilde{b}_{r+1}$, ..., $\\tilde{b}_{m}$ are all zero\n",
    "        - One unique solution if consistent and $r=n$\n",
    "        - Infinite many solution if consistent and $r<n$. In this case, choose $x_{r+1}$, ...,$x_n$ arbitrarily.\n",
    "    - Inconsistent if $r<m$ and at least one of $\\tilde{b}_{r+1}$, ..., $\\tilde{b}_{m}$ is non-zero\n",
    "        - No solution "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b295b564",
   "metadata": {},
   "source": [
    "## Linear Independence, Rank of Matrix, Vector Space\n",
    "### Linear Independence\n",
    "- Given: Set of vectors {$\\mathbf{v}^{(1)},\\mathbf{v}^{(2)},\\cdots,\\mathbf{v}^{(n)}$}\n",
    "- With $c_1,c_2,\\cdots,c_n$ are scalars, a linear combination of these vectors is of the form:\n",
    "$$c_1\\mathbf{v}^{(1)}+c_2\\mathbf{v}^{(2)}+\\cdots+c_n\\mathbf{v}^{(n)}$$\n",
    "- Consider $c_1\\mathbf{v}^{(1)}+c_2\\mathbf{v}^{(2)}+\\cdots+c_n\\mathbf{v}^{(n)}=0$ true for $c_1=c_2=\\cdots=c_n=0$\n",
    "    - If this is the only solution:**This set of vectors form a linear independent set**\n",
    "    - Otherwise: **Linear Dependent**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6c120d",
   "metadata": {},
   "source": [
    "### Rank of a matrix\n",
    "- The rank of a matrix $\\mathbf{A}$ is the number of linearly independent row vectors of $\\mathbf{A}$,\n",
    "- Denoted by **rank A**\n",
    "- Determine the rank of a matrix\n",
    "    - Observation: Number of linearly independent row vectors does not change by elementary row operations\n",
    "    - **Theorem 1**: \n",
    "        - Row equivalent matrices have the same rank\n",
    "    - Strategy: Reduce the matrix to row-echelon form (upper triangular form) and read off the rank directly\n",
    "    - **Theorem 2**: \n",
    "        - $p$ vectors with $n$ components each are independent if the matrix with these vectors as row vectors has rank $p$, but linearly dependent if that rank is less than $p$\n",
    "    - **Theorem 3**: \n",
    "        - The rank of a matrix $\\mathbf{A}$ equals the maximum number of linearly independent column vectors of $\\mathbf{A}$. Hence $\\mathbf{A}$ and its transpose $\\mathbf{A}^T$ have the same rank\n",
    "    - **Theorem 4**:\n",
    "        - $p$ vectors with $n<p$ components are always linearly dependent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4fc767",
   "metadata": {},
   "source": [
    "### Vector Space\n",
    "- **Vector Space**:\n",
    "    - Denoted by $V$\n",
    "    - Also called a **linear space**\n",
    "    - Nonempty set of vectors with the same number of components such that with any two vectors $\\mathbf{a}$ and $\\mathbf{b}$, all linear combinations $\\alpha\\mathbf{a}+\\beta\\mathbf{b}$ ($\\alpha,\\beta$ are real numbers) are elements of $V$ and these vectors satisfy the rules for vector addition and scalar multiplication.\n",
    "- **Dimension** of $V$:\n",
    "    - Maximal number of linearly independent vectors\n",
    "- **Basis**:\n",
    "    - Linear independent set of maximally possible vectors\n",
    "    - Number of vectors in the basis = dim $V$\n",
    "- **Span**:\n",
    "    - Set of all linear combinations given vectors $\\mathbf{a_1},\\mathbf{a_2},\\cdots,\\mathbf{a_p}$\n",
    "- **Subspace**:\n",
    "    - Nonempty set of vectors which forms itself a vector space with respect to addition and scalar multiplication\n",
    "- **Theorem 5**:\n",
    "    - The vector space $\\mathbb{R}^n$ consisting of all vectors with $n$ components (real) has dimension $n$ \n",
    "- **Theorem 6**:\n",
    "    - The row space and the column space of a matrix $\\mathbf{A}$ have the same dimension, equal to rank $\\mathbf{A}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ae0a24",
   "metadata": {},
   "source": [
    "## Solution of linear systems: Existence, Uniqueness\n",
    "### Submatrix of a matrix $\\mathbf{A}$\n",
    "- Any matrix obtained from $\\mathbf{A}$ by omitting some rows or columns\n",
    "\n",
    "### Theorems for linear systems(homogeneous systems)\n",
    "- **Homogeneous systems**\n",
    "    - A linear system of $m$ equations and $n$ unknowns in the form $$\\mathbf{Ax}=0$$\n",
    "    where $\\mathbf{A}\\in \\mathbb{R}^{m\\times n}$, $\\mathbf{x}\\in \\mathbb{R}^n$\n",
    "- Always has the trivial solution $\\mathbf{x}=0$\n",
    "- Nontrivial solutions exist if and only if rank $\\mathbf{A}=r<n$ \n",
    "- If $r<n$, the solution, together with $\\mathbf{x}=0$, form a vector space of dimension $n-r$, called the solution space of the system\n",
    "- In particular, if $\\mathbf{x}_1$ and $\\mathbf{x}_2$ are solution vectors, so is $\\mathbf{x}=c_1\\mathbf{x}_1+c_2\\mathbf{x}_2$\n",
    "- Solution space of the system is called **Null Space**, $\\mathbf{Ax}=0$ for every $\\mathbf{x}$ from this solution space $N$\n",
    "    - dim $N$ = **Nullity**\n",
    "    - rank $\\mathbf{A}$ + nullity $\\mathbf{A}$ = $n$\n",
    "- A homogeneous system with fewer equations than unknowns always has non-trivial solution\n",
    "    - rank $\\mathbf{A}=r\\le m <n$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba952ca",
   "metadata": {},
   "source": [
    "### Theorems for linear systems (non-homogeneous systems)\n",
    "- **Non-homogeneous systems**:\n",
    "    - A linear system of $m$ equations and $n$ unknowns in the form $$\\mathbf{Ax}=\\mathbf{b}$$\n",
    "    where $\\mathbf{A}\\in \\mathbb{R}^{m\\times n}$, $\\mathbf{x}\\in \\mathbb{R}^n$, $\\mathbf{b}\\in \\mathbb{R}^m$ and $\\mathbf{b}\\ne 0$\n",
    "- **Existence**:\n",
    "    - A non-homogeneous linear system is consistent (i.e. has solutions) if and only if the coefficient matrix $\\mathbf{A}$ and the augmented matrix $\\tilde{\\mathbf{A}}$ have the same rank.\n",
    "- **Uniqueness**:\n",
    "    - The system has precisely one solution if and only if the common rank $r$ of $\\mathbf{A}$ and $\\tilde{\\mathbf{A}}$ equals $n$\n",
    "- **Infinite many solutions**\n",
    "    - If this common rank is less than $n$, the system has infinitely many solutions. All the solutions can be obtained by determining $r$ unknowns in terms of the remaining $n-r$ unknowns.\n",
    "- **Solution**\n",
    "    - If a non-homogeneous system is consistent, then all the solutions are obtained as $\\mathbf{x}=\\mathbf{x}_o+\\mathbf{x}_h$\n",
    "        - $\\mathbf{x}_o$: Fixed solution of $\\mathbf{Ax}=\\mathbf{b}$\n",
    "        - $\\mathbf{x}_h$: Run through all solutions of $\\mathbf{Ax}=0$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702017ac",
   "metadata": {},
   "source": [
    "## Determinants, Cramer's Rule\n",
    "### Determinant of order n\n",
    "- **Only defined for a square matrix**\n",
    "- $D=\\mathrm{det}\\mathbf{A}=\\begin{vmatrix}a_{1,1}&a_{1,2}&\\cdots&a_{1,n}\\\\a_{2,1}&a_{2,2}&\\cdots&a_{2,n}\\\\\\vdots&\\vdots&\\ddots&\\cdots\\\\a_{n,1}&a_{n,2}&\\cdots&a_{n,n}\\end{vmatrix}$\n",
    "- $n=1$, $D=a_1$\n",
    "- $n\\ge 2$,expand by $i-th$ rows ($i=1,2,\\cdots,n$)\n",
    "    - $D = a_{i,1}C_{i,1}+a_{i,2}C_{i,2}+\\cdots+a_{i,n}C_{i,n}$\n",
    "        - $C_{i,j}=(-1)^{i+j}M_{i,j}$\n",
    "        - $M_{i,j}$ is the determinant of order $n-1$, of a submatrix of $\\mathbf{A}$ obtained from $\\mathbf{A}$ by deleting the $i$-th row and the $j$-th column as indicated by the entry $a_{i,j}$\n",
    "    - $D = \\underset{j=1}{\\overset{n}{\\Sigma}}a_{i,j}C_{i,j}$ \n",
    "    - Or alternatively expand by $j-th$ column: $D = \\underset{i=1}{\\overset{n}{\\Sigma}}a_{i,j}C_{i,j}$ where $j=1,2,\\cdots,n$\n",
    "    - **Remark**: Easier for n upper triangular matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401f1bdb",
   "metadata": {},
   "source": [
    "### General properties of determinants\n",
    "- Behavior of $n$-th order determinant under elementary row operations\n",
    "    - Interchange of two rows or two columns multiplies the determinant by $-1$\n",
    "    - Addition of a multiple of one row/column to another row/column doesn't alter the value of the determinant\n",
    "    - Multiplication of a row/column by a constant $c$ multiplies the value of the determinant by $c$\n",
    "        - $\\mathrm{det}(c\\mathbf{A})=c^n\\mathrm{det}(\\mathbf{A})$\n",
    "        - $\\mathrm{det}(\\mathbf{A}^T)=\\mathrm{det}(\\mathbf{A})$\n",
    "        - $\\mathrm{det}(\\mathbf{AB})=\\mathrm{det}(\\mathbf{A})\\mathrm{det}(\\mathbf{B})$\n",
    "        - $\\mathrm{det}(\\mathbf{A+B})\\ne \\mathrm{det}(\\mathbf{A})+\\mathrm{det}(\\mathbf{B})$ (In general)\n",
    "    - Transposition leaves determinant the same\n",
    "    - A zero row or zero column renders the value of $\\mathrm{det}=0$\n",
    "    - Proportional rows or columns render the value of $\\mathrm{det}=0$\n",
    "- For practical purposes, to evaluate a determinant of $n$-th order:\n",
    "    - reduce the matrix to upper triangular form, which need to keep track of operations that change the determinant\n",
    "    - multiply the elements on the diagonal to calculate the determinant\n",
    "- Relationship between **Rank** and **Determinant**\n",
    "    - An $m\\times n$ matrix $\\mathbf{A}=[A_{i,j}]$ has rank $r\\ge 1$ if and only if it has an $r\\times r$ submatrix with non-zero determinant\n",
    "    - In particular, if $\\mathbf{A}$ is square with size $n\\times n$, it has $\\mathrm{rank}=n$ if and only if $\\mathrm{det}\\ne 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca04699",
   "metadata": {},
   "source": [
    "### Cramer's rule (Solution of linear system by determinants)\n",
    "- If a linear system of $n$ equations for $n$ unknowns:$$\\mathbf{Ax}=\\mathbf{b}$$\n",
    "    where $\\mathbf{A}\\in \\mathbb{R}^{n\\times n}$, $\\mathbf{x}\\in \\mathbb{R}^n$, $\\mathbf{b}\\in \\mathbb{R}^n$ has non-zero coefficient determinant ($\\mathrm{det}(\\mathbf{A})=D\\ne 0$), it has precisely one solution\n",
    "- The solution is given by $x_1=\\frac{D_1}{D},x_2=\\frac{D_2}{D},\\cdots,x_n=\\frac{D_n}{D}$ where $D_k$ is the determinant of a matrix obtained from $\\mathbf{A}$ by replacing the $j$-th column by a column with entries $b_1,b_2,\\cdots,b_n$\n",
    "- If the system is homogeneous and $D\\ne 0$, it has only the trivial solution. If $D=0$, the system has non-trivial solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bad194",
   "metadata": {},
   "source": [
    "## Inverse of matrix, Gauss-Jordan eliminations\n",
    "### Inverse of matrix\n",
    "- Consider only square matrices\n",
    "- Inverse of an $n\\times n$ matrix $\\mathbf{A}=[A_{i,j}]$ is $\\mathbf{A}^{-1}$ such that:\n",
    "$$\\mathbf{A}\\mathbf{A}^{-1}=\\mathbf{A}^{-1}\\mathbf{A}=\\mathbf{I}_n$$\n",
    "- If $\\mathbf{A}$ has inverse: $\\mathbf{A}$ is non-singular, otherwise $\\mathbf{A}$ is singular\n",
    "    - Singular matrices are similar to zeros (similar to the idea that $0$ does not have an inverse)\n",
    "    - Called \"singular\" because a random matrix is unlikely to be singular just like choosing a random number is unlikely to be $0$\n",
    "- Motivation:\n",
    "    - $\\mathbf{Ax}=\\mathbf{b}\\Rightarrow \\mathbf{x}=\\mathbf{A}^{-1}\\mathbf{b}$ (usually not suitable for numerical calculation)\n",
    "- **Theorem**: Existence of $\\mathbf{A}^{-1}$\n",
    "    - The inverse $\\mathbf{A}^{-1}$ of an $n\\times n$ matrix $\\mathbf{A}$ exists if and only if the $\\mathrm{rank}\\mathbf{A}=n$, thus if and only if $\\mathrm{det}\\mathbf{A}\\ne 0$ \n",
    "- Formula for Inverse of $\\mathbf{A}$\n",
    "    - $\\mathbf{A}^{-1}=\\frac{1}{\\mathrm{det}\\mathbf{A}}[C_{i,j}]^T$\n",
    "    - $C_{i,j}=(-1)^{i+j}M_{i,j}$\n",
    "    - $M_{i,j}$ is the determinant of order $n-1$, of a submatrix of $\\mathbf{A}$ obtained from $\\mathbf{A}$ by deleting the $i$-th row and the $j$-th column as indicated by the entry $a_{i,j}$\n",
    "    - Usually used on only $2\\times 2$ matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f046cb16",
   "metadata": {},
   "source": [
    "### Gauss-Jordan elimination\n",
    "- Method to find the inverse\n",
    "- Build an matrix $[\\mathbf{A}|\\mathbf{I}]$ containing $\\mathbf{A}$ and identity matrix $\\mathbf{I}$\n",
    "- Perform Gaussian elimination on $\\mathbf{A}$, but do the same steps on $\\mathbf{I}$, until get the result $[\\mathbf{I}|\\mathbf{B}]$. Thus, $\\mathbf{B}=\\mathbf{A}^{-1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba3060b",
   "metadata": {},
   "source": [
    "## Norms\n",
    "### Definition\n",
    "- The \"size\" of a vector or matrix. \n",
    "- Intuitively,the norm of a vector $\\mathbf{x}$ measures the distance from the origin to the point $\\mathbf{a}$.\n",
    "- Functions mapping vectors or matrices to non-negative values\n",
    "- Formally, a norm is any function $f$ that satisfies the following properties:\n",
    "    - $f(\\mathbf{x})=0\\Rightarrow \\mathbf{x}=0$\n",
    "    - $f(\\mathbf{x}+\\mathbf{y})\\le f(\\mathbf{x})+f(\\mathbf{y})$ (the triangle inequality)\n",
    "    - $\\forall \\alpha \\in \\mathbb{R},f(\\alpha\\mathbf{x})=|\\alpha|f(\\mathbf{x})$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71570f43",
   "metadata": {},
   "source": [
    "### $L^p$ norm\n",
    "- $||\\mathbf{x}||_p=\\left(\\underset{i}{\\Sigma}|x_i|^p\\right)^{\\frac{1}{p}}$\n",
    "- $p=2$: **Euclidean Norm**, used so frequently in machine learning that it is often denoted simply as $||\\mathbf{x}||$ with the subscript $2$ omitted. It is also common to measure the size of a vector using the squared $L^2$ norm, which can be calculated simply as $\\mathbf{x}^T\\mathbf{x}$\n",
    "    - In most machine learning cases, the squared $L^2$ norm is more convenient to work with mathematically and computationally than the $L^2$ norm itself. On example is that each derivative of the squared $L^2$ norm with respect to each element of $\\mathbf{x}$ depends only on the corresponding element of $\\mathbf{x}$.\n",
    "- $p=1$: commonly used in machine learning when the difference between zero and nonzero elements is very important. Every time an element of $\\mathbf{x}$ moves away from 0 by $\\epsilon$, the $L^1$ norm increases by $\\epsilon$\n",
    "    - Sometimes used to count the number of nonzero entries\n",
    "- $p=\\infty$:**Max Norm**, simplifies to the absolute value of the element with the largest magnitude in the vector \n",
    "    $$\n",
    "    ||\\mathbf{x}||_{\\infty}=\\underset{i}{\\mathrm{max}}|\\mathbf{x}_i|\n",
    "    $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505ed1db",
   "metadata": {},
   "source": [
    "### Frobenius Norm\n",
    "- Used to measure the size of a matrix\n",
    "- $||\\mathbf{A}||_{F}=\\sqrt{\\underset{i,j}{\\Sigma}A^2_{i,j}}$\n",
    "- Analogous to the $L^2$ norm of a vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43920d91",
   "metadata": {},
   "source": [
    "## Inner Product Space, Linear Transformations\n",
    "### Inner Product\n",
    "- A binary operation associates each pair of vectors in the space with a scalar quantity known as the inner product of the vectors, often denoted using angle brackets (as in ${\\displaystyle \\langle \\mathbf{a},\\mathbf{b}\\rangle}$).\n",
    "- **Dot product**: One widely used inner product on a finite dimensional Euclidean space. Apply for two vectors with the same length.\n",
    "    - $\\langle\\mathbf{a},\\mathbf{b}\\rangle=(\\mathbf{a},\\mathbf{b})=\\mathbf{a}\\bullet\\mathbf{b}=\\mathbf{a}^T\\mathbf{b}=\\underset{i=1}{\\overset{n}{\\Sigma}}a_ib_i$\n",
    "    - Two vectors $\\mathbf{a}, \\mathbf{b}$ are called **orthogonal** if $\\mathbf{a}\\bullet\\mathbf{b}=0$\n",
    "    - Can be written in terms of norms: $\\mathbf{a}^T\\mathbf{b}=||a||_2||b||_2\\mathrm{cos}\\theta$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54fe199",
   "metadata": {},
   "source": [
    "### Abstract Real Inner Product Space\n",
    "- Real vector space $V$ is called real inner product space $V$ together with an inner product $(\\mathbf{a},\\mathbf{b})$ satisfying\n",
    "    - Linearity: $(q_1\\mathbf{a}+q_2\\mathbf{b},\\mathbf{c})=q_1(\\mathbf{a},\\mathbf{c})+q_2(\\mathbf{b},\\mathbf{c})$ where $\\mathbf{a},\\mathbf{b}\\in V, q_1,q_2\\in \\mathbb{R}$\n",
    "    - Symmetry: $(\\mathbf{a},\\mathbf{b})=(\\mathbf{b},\\mathbf{a})$\n",
    "    - Positive-definite: $(\\mathbf{a},\\mathbf{a})\\ge 0$, $(\\mathbf{a},\\mathbf{a})=0$ if and only if $\\mathbf{a}=0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc55501",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
